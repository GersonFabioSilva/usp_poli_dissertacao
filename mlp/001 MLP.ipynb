{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Inicialização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import  torch\n",
        "import  torch.nn as nn\n",
        "import  torch.nn.functional as F\n",
        "import  torch.optim as optim\n",
        "import  psutil\n",
        "import  os\n",
        "import joblib\n",
        "import  warnings\n",
        "import  pandas as pd\n",
        "import  seaborn as sns\n",
        "\n",
        "import ctypes\n",
        "import snap7\n",
        "import ctypes\n",
        "#from snap7.types import Areas, S7DataItem, S7WLWord, S7WLReal, S7WLTimer\n",
        "from snap7.type import S7DataItem, Area, WordLen\n",
        "from snap7.util import set_int, set_real, get_int, get_real, get_s5time\n",
        "\n",
        "import  numpy as np\n",
        "import  matplotlib.pyplot as plt\n",
        "\n",
        "import  time\n",
        "#from    kan import *\n",
        "from    sklearn.model_selection import train_test_split\n",
        "from    sklearn.metrics import confusion_matrix, classification_report\n",
        "from    sklearn.ensemble import RandomForestClassifier\n",
        "from    sklearn.preprocessing import LabelEncoder\n",
        "from    sklearn.model_selection import GridSearchCV\n",
        "from    sklearn.preprocessing import StandardScaler\n",
        "from    sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from    imblearn.over_sampling import SMOTE\n",
        "from    imblearn.under_sampling import RandomUnderSampler\n",
        "from    imblearn.pipeline import Pipeline\n",
        "from    imblearn.combine import SMOTETomek\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Carregar e Preparar Conjunto de Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UDI</th>\n",
              "      <th>Product ID</th>\n",
              "      <th>Type</th>\n",
              "      <th>Air temperature [K]</th>\n",
              "      <th>Process temperature [K]</th>\n",
              "      <th>Rotational speed [rpm]</th>\n",
              "      <th>Torque [Nm]</th>\n",
              "      <th>Tool wear [min]</th>\n",
              "      <th>Target</th>\n",
              "      <th>Failure Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>M14860</td>\n",
              "      <td>M</td>\n",
              "      <td>298.1</td>\n",
              "      <td>308.6</td>\n",
              "      <td>1551</td>\n",
              "      <td>42.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>No Failure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>L47181</td>\n",
              "      <td>L</td>\n",
              "      <td>298.2</td>\n",
              "      <td>308.7</td>\n",
              "      <td>1408</td>\n",
              "      <td>46.3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>No Failure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>L47182</td>\n",
              "      <td>L</td>\n",
              "      <td>298.1</td>\n",
              "      <td>308.5</td>\n",
              "      <td>1498</td>\n",
              "      <td>49.4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>No Failure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>L47183</td>\n",
              "      <td>L</td>\n",
              "      <td>298.2</td>\n",
              "      <td>308.6</td>\n",
              "      <td>1433</td>\n",
              "      <td>39.5</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>No Failure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>L47184</td>\n",
              "      <td>L</td>\n",
              "      <td>298.2</td>\n",
              "      <td>308.7</td>\n",
              "      <td>1408</td>\n",
              "      <td>40.0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>No Failure</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   UDI Product ID Type  Air temperature [K]  Process temperature [K]  \\\n",
              "0    1     M14860    M                298.1                    308.6   \n",
              "1    2     L47181    L                298.2                    308.7   \n",
              "2    3     L47182    L                298.1                    308.5   \n",
              "3    4     L47183    L                298.2                    308.6   \n",
              "4    5     L47184    L                298.2                    308.7   \n",
              "\n",
              "   Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Target Failure Type  \n",
              "0                    1551         42.8                0       0   No Failure  \n",
              "1                    1408         46.3                3       0   No Failure  \n",
              "2                    1498         49.4                5       0   No Failure  \n",
              "3                    1433         39.5                7       0   No Failure  \n",
              "4                    1408         40.0                9       0   No Failure  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# dados importados da plataforma KAGGLE - https://www.kaggle.com/datasets/shivamb/machine-predictive-maintenance-classification\n",
        "df = pd.read_csv(\"predictive_maintenance.csv\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* descartar as colunas desnecessárias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "df=df.drop(['Product ID','UDI','Target'],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* codificar a coluna de falhas para tipo int entre 0 e 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"'\\n0 - 112  - heat dissipation\\n1 - 9652 - no Failure\\n2 - 78   - overstrain\\n3 - 95   - power failure\\n4 - 18   - random failure\\n5 - 45   - tool wear\\n\""
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Perform label encoding\n",
        "df['Failure Type_encoded'] = label_encoder.fit_transform(df['Failure Type'])\n",
        "\n",
        "df['Failure Type_encoded'].value_counts()\n",
        "\n",
        "''''\n",
        "0 - 112  - heat dissipation\n",
        "1 - 9652 - no Failure\n",
        "2 - 78   - overstrain\n",
        "3 - 95   - power failure\n",
        "4 - 18   - random failure\n",
        "5 - 45   - tool wear\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* converter a coluna 'Type' (string) em outras duas separadas do tipo bool (uma para cada tipo de material) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Air temperature [K]</th>\n",
              "      <th>Process temperature [K]</th>\n",
              "      <th>Rotational speed [rpm]</th>\n",
              "      <th>Torque [Nm]</th>\n",
              "      <th>Tool wear [min]</th>\n",
              "      <th>Failure Type</th>\n",
              "      <th>Failure Type_encoded</th>\n",
              "      <th>Type_L</th>\n",
              "      <th>Type_M</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>298.1</td>\n",
              "      <td>308.6</td>\n",
              "      <td>1551</td>\n",
              "      <td>42.8</td>\n",
              "      <td>0</td>\n",
              "      <td>No Failure</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>298.2</td>\n",
              "      <td>308.7</td>\n",
              "      <td>1408</td>\n",
              "      <td>46.3</td>\n",
              "      <td>3</td>\n",
              "      <td>No Failure</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>298.1</td>\n",
              "      <td>308.5</td>\n",
              "      <td>1498</td>\n",
              "      <td>49.4</td>\n",
              "      <td>5</td>\n",
              "      <td>No Failure</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>298.2</td>\n",
              "      <td>308.6</td>\n",
              "      <td>1433</td>\n",
              "      <td>39.5</td>\n",
              "      <td>7</td>\n",
              "      <td>No Failure</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>298.2</td>\n",
              "      <td>308.7</td>\n",
              "      <td>1408</td>\n",
              "      <td>40.0</td>\n",
              "      <td>9</td>\n",
              "      <td>No Failure</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Air temperature [K]  Process temperature [K]  Rotational speed [rpm]  \\\n",
              "0                298.1                    308.6                    1551   \n",
              "1                298.2                    308.7                    1408   \n",
              "2                298.1                    308.5                    1498   \n",
              "3                298.2                    308.6                    1433   \n",
              "4                298.2                    308.7                    1408   \n",
              "\n",
              "   Torque [Nm]  Tool wear [min] Failure Type  Failure Type_encoded  Type_L  \\\n",
              "0         42.8                0   No Failure                     1   False   \n",
              "1         46.3                3   No Failure                     1    True   \n",
              "2         49.4                5   No Failure                     1    True   \n",
              "3         39.5                7   No Failure                     1    True   \n",
              "4         40.0                9   No Failure                     1    True   \n",
              "\n",
              "   Type_M  \n",
              "0    True  \n",
              "1   False  \n",
              "2   False  \n",
              "3   False  \n",
              "4   False  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.get_dummies(df, columns=['Type'], prefix='Type', drop_first=True)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* separar os dados em: dados de entrada (features), X  e dados de saída (label), y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[298.4 308.3 1433 62.3 20 True False]\n",
            "3\n"
          ]
        }
      ],
      "source": [
        "# Definição do conjunto de dados de entrada e do conjunto de dados de saída\n",
        "\n",
        "X_raw = df.drop(['Failure Type','Failure Type_encoded'], axis=1).values\n",
        "y_raw= df['Failure Type_encoded'].values\n",
        "\n",
        "print(X_raw[168])\n",
        "print(y_raw[168])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Em aplicações do mundo real, a modelagem de classificação frequentemente enfrenta o problema de conjuntos de dados desequilibrados, onde o número de instâncias da classe majoritária é muito maior do que o da classe minoritária, o que dificulta o aprendizado adequado do modelo em relação à classe minoritária. Isso se torna um problema sério quando a informação contida na classe minoritária é mais importante como, por exemplo, no conjunto utilizado.\n",
        "\n",
        "* Uma das abordagens populares para resolver o problema de conjuntos de dados desequilibrados é a superamostragem da classe minoritária ou a subamostragem da classe majoritária. No entanto, essas abordagens possuem suas próprias limitações. No método tradicional de superamostragem, a ideia é duplicar aleatoriamente alguns exemplos da classe minoritária — essa técnica não adiciona novas informações ao conjunto de dados. Por outro lado, o método de subamostragem é realizado removendo aleatoriamente alguns exemplos da classe majoritária, o que resulta na perda de algumas informações originais dos dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de amostras antes balanceamento: 10000\n",
            "Total de amostras por falha:\n",
            "\n",
            " Failure Type_encoded\n",
            "1    9652\n",
            "0     112\n",
            "3      95\n",
            "2      78\n",
            "5      45\n",
            "4      18\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print('Total de amostras antes balanceamento:',df['Failure Type_encoded'].count())\n",
        "print('Total de amostras por falha:\\n\\n', df['Failure Type_encoded'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Uma solução para superar essas limitações é gerar novos exemplos sintetizados a partir da classe minoritária existente. Esse método é conhecido como Técnica de Superamostragem da Minoria Sintética (SMOTE). Existem muitas variações do SMOTE, mas neste artigo será explicado o método SMOTE-Tomek Links e sua implementação em Python. Esse método combina a superamostragem do SMOTE com a subamostragem dos Tomek Links.\n",
        "\n",
        "* O método SMOTE-Tomek Links, desenvolvido por Chawla et al. (2002) é uma combinação de técnicas que visa equilibrar os dados ao aumentar a representatividade da classe minoritária através da criação de novos exemplos sintéticos e ao mesmo tempo remover exemplos que são considerados ruidosos ou redundantes na classe majoritária. A implementação desta abordagem utilizando Python é apresentada, detalhando os passos e a lógica do algoritmo, assim como os resultados obtidos em diferentes conjuntos de dados desequilibrados.\n",
        "\n",
        "* A combinação das técnicas de superamostragem e subamostragem, especificamente utilizando o método SMOTE-Tomek Links, mostra-se eficaz na melhoria do desempenho dos modelos de classificação em conjuntos de dados desequilibrados. Esta abordagem permite ao modelo aprender de forma mais eficiente a partir da classe minoritária, mantendo a integridade e a diversidade da informação no conjunto de dados.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de amostras após balanceamento: 57868\n",
            "Total de amostras por falha:\n",
            "\n",
            " Type_encoded\n",
            "2    9652\n",
            "0    9649\n",
            "5    9647\n",
            "3    9645\n",
            "4    9645\n",
            "1    9630\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#implementação do método SMOTE no conunto de dados\n",
        "smt=SMOTETomek(sampling_strategy='auto',random_state=42)\n",
        "X_resampled, y_resampled = smt.fit_resample(X_raw, y_raw)\n",
        "\n",
        "# Convertendo para dataframe do pandas\n",
        "df_resampled = pd.DataFrame(X_resampled, columns=[f'feature_{i}' for i in range(X_resampled.shape[1])])\n",
        "df_resampled['Type_encoded'] = y_resampled \n",
        "\n",
        "df_resampled.head()\n",
        "\n",
        "#distribuição das classes após balanceamento\n",
        "print('Total de amostras após balanceamento:',df_resampled['Type_encoded'].count())\n",
        "print('Total de amostras por falha:\\n\\n', df_resampled['Type_encoded'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Temp_Ar</th>\n",
              "      <th>Temp_Pr</th>\n",
              "      <th>Vel_Spindle</th>\n",
              "      <th>Torque</th>\n",
              "      <th>Desg_Ferr</th>\n",
              "      <th>Mat_L</th>\n",
              "      <th>Mat_M</th>\n",
              "      <th>Tipo_Falha</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>298.1</td>\n",
              "      <td>308.6</td>\n",
              "      <td>1551.0</td>\n",
              "      <td>42.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>298.2</td>\n",
              "      <td>308.7</td>\n",
              "      <td>1408.0</td>\n",
              "      <td>46.3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>298.1</td>\n",
              "      <td>308.5</td>\n",
              "      <td>1498.0</td>\n",
              "      <td>49.4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>298.2</td>\n",
              "      <td>308.6</td>\n",
              "      <td>1433.0</td>\n",
              "      <td>39.5</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>298.2</td>\n",
              "      <td>308.7</td>\n",
              "      <td>1408.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Temp_Ar  Temp_Pr  Vel_Spindle  Torque  Desg_Ferr  Mat_L  Mat_M  Tipo_Falha\n",
              "0    298.1    308.6       1551.0    42.8        0.0    0.0    1.0           1\n",
              "1    298.2    308.7       1408.0    46.3        3.0    1.0    0.0           1\n",
              "2    298.1    308.5       1498.0    49.4        5.0    1.0    0.0           1\n",
              "3    298.2    308.6       1433.0    39.5        7.0    1.0    0.0           1\n",
              "4    298.2    308.7       1408.0    40.0        9.0    1.0    0.0           1"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_resampled = df_resampled.rename(columns={'feature_0':'Temp_Ar'})\n",
        "df_resampled = df_resampled.rename(columns={'feature_1':'Temp_Pr'})\n",
        "df_resampled = df_resampled.rename(columns={'feature_2':'Vel_Spindle'})\n",
        "df_resampled = df_resampled.rename(columns={'feature_3':'Torque'})\n",
        "df_resampled = df_resampled.rename(columns={'feature_4':'Desg_Ferr'})\n",
        "df_resampled = df_resampled.rename(columns={'feature_5':'Mat_L'})\n",
        "df_resampled = df_resampled.rename(columns={'feature_6':'Mat_M'})\n",
        "\n",
        "df_resampled = df_resampled.rename(columns={'Type_encoded':'Tipo_Falha'})\n",
        "\n",
        "df_resampled.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Metodo para normalização do conjunto de dados e formatação para as diferentes redes neurais (MLP e KAN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_Preditive_Maintenance_Dataset():\n",
        "\n",
        "    X_ = df_resampled.drop(['Tipo_Falha'], axis=\"columns\")\n",
        "\n",
        "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "    X_   = scaler.fit_transform(X_)    \n",
        "    joblib.dump(scaler, 'minmax_scaler.pkl')    \n",
        "\n",
        "    y_ = df_resampled['Tipo_Falha']\n",
        "\n",
        "    #convertendo os dados em tensores e atribuindo a sua excucção na CPU ou GPU (device) conforme disponibilidade avaliada no inicio do programa\n",
        "    X = torch.tensor(X_, dtype = torch.float32).to(device)\n",
        "    y = torch.tensor(y_.values, dtype = torch.long).to(device)  \n",
        "\n",
        "    #separa os dados entre conjunto de dados para treinamento (80%) e conjunto de dados para teste/validação (20% <-> teste_size=0.2)\n",
        "    train_data, test_data, train_target, test_target = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # geração de  mini batches para melhorar desempenho do treinamento\n",
        "    train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_data, train_target), batch_size=10, shuffle=True)   \n",
        "    validation_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_data, test_target), batch_size=10, shuffle=False)  \n",
        "\n",
        "    #conjunto de dados no formato a ser utilizado no redes MLP\n",
        "    train_data    = train_loader\n",
        "    test_data     = validation_loader\n",
        "    MLP_dataset   = [train_data, test_data]  \n",
        "\n",
        "    return MLP_dataset\n",
        "\n",
        "dataset =load_Preditive_Maintenance_Dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Implementação Rede Neural Multilayer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\'\\'\\nclass MLP_Model(nn.Module):  \\n    \\n    def __init__(self, entrada, camada01, camada02, camada03, saida):\\n        super(MLP_Model, self).__init__()\\n        self.fc1 = nn.Linear(entrada, camada01)\\n        self.fc2 = nn.Linear(camada01, camada02)\\n        self.fc3 = nn.Linear(camada02, camada03)\\n        self.fc4 = nn.Linear(camada03, saida)\\n        \\n    def forward(self, x):\\n        x = F.relu(self.fc1(x))\\n        x = F.relu(self.fc2(x))\\n        x = F.relu(self.fc3(x))\\n        x = self.fc4(x)\\n        return x\\n    \\ndef train(model, train_loader, criterion, optimizer, num_epochs):\\n    model.train()\\n    \\n    ram_usage=[]\\n    cpu_usage=[]\\n    backprop_time=[]\\n    loss_list=[]\\n\\n    startMLP_train = time.time()\\n    \\n    for epoch in range(num_epochs):  \\n\\n        for inputs, labels in train_loader:\\n            inputs, labels = inputs.to(device), labels.to(device) \\n            optimizer.zero_grad()            \\n            outputs = model(inputs)\\n            loss = criterion(outputs, labels)\\n            startMLP_bwd = time.time()\\n            loss.backward()        \\n            endMLP_bwd = time.time()\\n            backprop_time.append((endMLP_bwd-startMLP_bwd)*1000)\\n            optimizer.step()\\n\\n        loss_list.append(loss)\\n        ram_usage.append(psutil.cpu_percent(4))\\n        cpu_usage.append(psutil.virtual_memory()[3]/1000000000)\\n        print(\\'\\x1b[K\\',f\\'Epoch {epoch+1}/{num_epochs} | Loss: {round(loss.item(), 15)} | Backpropagation Time: {round(backprop_time[-1],2)} ms | CPU Usage: {round(cpu_usage[-1],2)} % | RAM Usage: {round(ram_usage[-1],2)} GB\\', end=\"\\r\")\\n\\n    endMLP_train = time.time()\\n    train_time = endMLP_train - startMLP_train\\n    backpropagation_time = np.max(backprop_time)\\n    train_cpu_usage = np.max(cpu_usage)   \\n    train_ram_usage = np.max(ram_usage)\\n\\n    info = {\\'Num_Epochs\\': num_epochs,\\n            \\'Back_Propagation_Time\\': backpropagation_time,\\n            \\'Max_CPU_usage\\': train_cpu_usage,\\n            \\'Max_RAM_usage\\' : train_ram_usage,\\n            \\'Train_Time\\' : train_time,\\n            \\'Loss_List\\': loss_list }\\n\\n    return info\\n\\ndef test_model(model, test_loader):\\n    model.eval()\\n    correct = 0\\n    total = 0\\n    with torch.no_grad():\\n        for inputs, labels in test_loader:\\n            inputs, labels = inputs.to(device), labels.to(device) \\n            outputs = model(inputs)\\n            _, predicted = torch.max(outputs.data, 1)\\n            total += labels.size(0)\\n            correct += (predicted == labels).sum().item()\\n    accuracy = 100 * correct / total\\n    print(f\\'Accuracy: {accuracy}%\\')\\n\\ndef count_parameters(model):\\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\\n\\n'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''''\n",
        "class MLP_Model(nn.Module):  \n",
        "    \n",
        "    def __init__(self, entrada, camada01, camada02, camada03, saida):\n",
        "        super(MLP_Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(entrada, camada01)\n",
        "        self.fc2 = nn.Linear(camada01, camada02)\n",
        "        self.fc3 = nn.Linear(camada02, camada03)\n",
        "        self.fc4 = nn.Linear(camada03, saida)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "    \n",
        "def train(model, train_loader, criterion, optimizer, num_epochs):\n",
        "    model.train()\n",
        "    \n",
        "    ram_usage=[]\n",
        "    cpu_usage=[]\n",
        "    backprop_time=[]\n",
        "    loss_list=[]\n",
        "\n",
        "    startMLP_train = time.time()\n",
        "    \n",
        "    for epoch in range(num_epochs):  \n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device) \n",
        "            optimizer.zero_grad()            \n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            startMLP_bwd = time.time()\n",
        "            loss.backward()        \n",
        "            endMLP_bwd = time.time()\n",
        "            backprop_time.append((endMLP_bwd-startMLP_bwd)*1000)\n",
        "            optimizer.step()\n",
        "\n",
        "        loss_list.append(loss)\n",
        "        ram_usage.append(psutil.cpu_percent(4))\n",
        "        cpu_usage.append(psutil.virtual_memory()[3]/1000000000)\n",
        "        print('\\033[K',f'Epoch {epoch+1}/{num_epochs} | Loss: {round(loss.item(), 15)} | Backpropagation Time: {round(backprop_time[-1],2)} ms | CPU Usage: {round(cpu_usage[-1],2)} % | RAM Usage: {round(ram_usage[-1],2)} GB', end=\"\\r\")\n",
        "\n",
        "    endMLP_train = time.time()\n",
        "    train_time = endMLP_train - startMLP_train\n",
        "    backpropagation_time = np.max(backprop_time)\n",
        "    train_cpu_usage = np.max(cpu_usage)   \n",
        "    train_ram_usage = np.max(ram_usage)\n",
        "\n",
        "    info = {'Num_Epochs': num_epochs,\n",
        "            'Back_Propagation_Time': backpropagation_time,\n",
        "            'Max_CPU_usage': train_cpu_usage,\n",
        "            'Max_RAM_usage' : train_ram_usage,\n",
        "            'Train_Time' : train_time,\n",
        "            'Loss_List': loss_list }\n",
        "\n",
        "    return info\n",
        "\n",
        "def test_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device) \n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy: {accuracy}%')\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"''\\nentrada     = 7\\ncamada_1    = 64\\ncamada_2    = 32\\ncamada_3    = 16\\nsaida       = 6\\n\\nmodel = MLP_Model(entrada, camada_1,camada_2,camada_3,saida).to(device)\\ncriterion = nn.CrossEntropyLoss()\\noptimizer = torch.optim.Adam(model.parameters(), lr=0.005)\\n\\n# Contar os parâmetros do modelo\\nnum_params = count_parameters(model)\\nprint(f'Número total de parâmetros treináveis: {num_params}')\\n\""
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''''\n",
        "entrada     = 7\n",
        "camada_1    = 64\n",
        "camada_2    = 32\n",
        "camada_3    = 16\n",
        "saida       = 6\n",
        "\n",
        "model = MLP_Model(entrada, camada_1,camada_2,camada_3,saida).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "\n",
        "# Contar os parâmetros do modelo\n",
        "num_params = count_parameters(model)\n",
        "print(f'Número total de parâmetros treináveis: {num_params}')\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MLP_Model(nn.Module):  \n",
        "    def __init__(self, layer_sizes):\n",
        "        super(MLP_Model, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        \n",
        "        for i in range(len(layer_sizes) - 1):\n",
        "            self.layers.append(nn.Linear(layer_sizes[i], layer_sizes[i + 1]))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        for layer in self.layers[:-1]:\n",
        "            x = F.relu(layer(x))\n",
        "        x = self.layers[-1](x)\n",
        "        return x\n",
        "    \n",
        "def train(model, train_loader, criterion, optimizer, num_epochs, device):\n",
        "    model.train()\n",
        "    \n",
        "    ram_usage = []\n",
        "    cpu_usage = []\n",
        "    backprop_time = []\n",
        "    loss_list = []\n",
        "\n",
        "    startMLP_train = time.time()\n",
        "    \n",
        "    for epoch in range(num_epochs):  \n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device) \n",
        "            optimizer.zero_grad()            \n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            startMLP_bwd = time.time()\n",
        "            loss.backward()        \n",
        "            optimizer.step()\n",
        "            endMLP_bwd = time.time()\n",
        "            backprop_time.append((endMLP_bwd - startMLP_bwd) * 1000)\n",
        "\n",
        "        loss_list.append(loss.item())\n",
        "        ram_usage.append(psutil.virtual_memory().percent)\n",
        "        cpu_usage.append(psutil.cpu_percent(interval=1))\n",
        "        print(f'Epoch {epoch+1}/{num_epochs} | Loss: {round(loss.item(), 4)} | Backpropagation Time: {round(backprop_time[-1], 2)} ms | CPU Usage: {round(cpu_usage[-1], 2)} % | RAM Usage: {round(ram_usage[-1], 2)} %', end=\"\\r\")\n",
        "\n",
        "    endMLP_train = time.time()\n",
        "    train_time = endMLP_train - startMLP_train\n",
        "    backpropagation_time = np.mean(backprop_time)\n",
        "    max_cpu_usage = np.max(cpu_usage)   \n",
        "    max_ram_usage = np.max(ram_usage)\n",
        "\n",
        "    info = {\n",
        "        'Num_Epochs': num_epochs,\n",
        "        'Back_Propagation_Time': backpropagation_time,\n",
        "        'Max_CPU_usage': max_cpu_usage,\n",
        "        'Max_RAM_usage': max_ram_usage,\n",
        "        'Train_Time': train_time,\n",
        "        'Loss_List': loss_list \n",
        "    }\n",
        "\n",
        "\n",
        "    return info\n",
        "\n",
        "def test_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device) \n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = round((100 * correct / total),4)\n",
        "    print(f'\\nAccuracy: {accuracy}%')\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Número total de parâmetros treináveis: 146\n"
          ]
        }
      ],
      "source": [
        "\n",
        "layers = [7, 10, 6] \n",
        "model = MLP_Model(layers).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_params = count_parameters(model)\n",
        "print(f'Número total de parâmetros treináveis: {num_params}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/2 | Loss: 0.2799 | Backpropagation Time: 0.65 ms | CPU Usage: 0.2 % | RAM Usage: 33.8 %\n",
            "Accuracy: 87.21%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "mlp_train_results = train(model, dataset[0], criterion, optimizer, num_epochs=2, device='cuda')\n",
        "\n",
        "test_model(model, dataset[1],device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MLP_loss_list = np.array([x.item() for x in mlp_train_results['Loss_List']]) \n",
        "iteration =  range(1, mlp_train_results['Num_Epochs']+1)        \n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(iteration, MLP_loss_list, marker='o', linestyle='-',  color='b', label='Erro Treino 1')\n",
        "\n",
        "plt.title('Evolução do Ajuste do Erro')\n",
        "plt.xlabel('Iterações')\n",
        "plt.ylabel('Erro')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "INFERÊNCIA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[299.2 309.1 1345 60.7 191 True False]]\n",
            "2\n",
            "Predicted classes:  tensor([2], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "X_2d= X_raw[2581].reshape(1, -1)\n",
        "\n",
        "print(X_2d)\n",
        "print(y_raw[2581])\n",
        "\n",
        "scaler = joblib.load('minmax_scaler.pkl')\n",
        "\n",
        "# Aplicar a normalização aos novos dados\n",
        "X_new_scaled = scaler.transform(X_2d)\n",
        "\n",
        "# Converter para tensor PyTorch\n",
        "X_new_scaled_tensor = torch.tensor(X_new_scaled, dtype=torch.float32)\n",
        "\n",
        "# Colocar o modelo em modo de avaliação\n",
        "model.eval()\n",
        "\n",
        "# Fazer a inferência\n",
        "with torch.no_grad():\n",
        "    output = model(X_new_scaled_tensor.to(device))\n",
        "\n",
        "    _, predicted = torch.max(output.data, 1)\n",
        "    print(\"Predicted classes: \", predicted)\n",
        "\n",
        "#print(output)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "7RE1svm9cXkX",
        "D7ERosp1iM17",
        "CBD58aME1Rvd",
        "tbhg0iWQ1FX-"
      ],
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.1.undefined"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
