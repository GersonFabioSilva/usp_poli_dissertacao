{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  warnings\n",
    "import  pandas as pd\n",
    "import  seaborn as sns\n",
    "import  numpy as np\n",
    "import  matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"grid_search_results_01.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>num_parameters</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>epoch_train_time</th>\n",
       "      <th>training_time</th>\n",
       "      <th>backpropagation_time</th>\n",
       "      <th>loss_min</th>\n",
       "      <th>max_cpu_usage</th>\n",
       "      <th>max_ram_usage</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>confusion_matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'batch_size': 256, 'dropout_prob': 0.0, 'epoc...</td>\n",
       "      <td>1798</td>\n",
       "      <td>64</td>\n",
       "      <td>0.535887</td>\n",
       "      <td>36.422380</td>\n",
       "      <td>1.194958</td>\n",
       "      <td>0.024936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>97.606705</td>\n",
       "      <td>0.975744</td>\n",
       "      <td>0.976670</td>\n",
       "      <td>0.976067</td>\n",
       "      <td>[[1893, 1, 0, 0, 0, 0], [23, 1739, 15, 25, 55,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'batch_size': 256, 'dropout_prob': 0.0, 'epoc...</td>\n",
       "      <td>1798</td>\n",
       "      <td>64</td>\n",
       "      <td>0.577678</td>\n",
       "      <td>36.345322</td>\n",
       "      <td>1.206922</td>\n",
       "      <td>0.111199</td>\n",
       "      <td>2.4</td>\n",
       "      <td>27.3</td>\n",
       "      <td>93.986522</td>\n",
       "      <td>0.938081</td>\n",
       "      <td>0.942167</td>\n",
       "      <td>0.939865</td>\n",
       "      <td>[[1843, 14, 23, 9, 0, 5], [38, 1467, 26, 34, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'batch_size': 256, 'dropout_prob': 0.0, 'epoc...</td>\n",
       "      <td>1798</td>\n",
       "      <td>64</td>\n",
       "      <td>0.664291</td>\n",
       "      <td>36.255791</td>\n",
       "      <td>1.194468</td>\n",
       "      <td>0.051083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.3</td>\n",
       "      <td>96.250216</td>\n",
       "      <td>0.961966</td>\n",
       "      <td>0.962541</td>\n",
       "      <td>0.962502</td>\n",
       "      <td>[[1868, 0, 26, 0, 0, 0], [35, 1671, 27, 13, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'batch_size': 256, 'dropout_prob': 0.0, 'epoc...</td>\n",
       "      <td>1798</td>\n",
       "      <td>64</td>\n",
       "      <td>0.519926</td>\n",
       "      <td>35.209785</td>\n",
       "      <td>1.137281</td>\n",
       "      <td>0.009414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.3</td>\n",
       "      <td>98.729912</td>\n",
       "      <td>0.987242</td>\n",
       "      <td>0.987249</td>\n",
       "      <td>0.987299</td>\n",
       "      <td>[[1894, 0, 0, 0, 0, 0], [11, 1859, 5, 11, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'batch_size': 256, 'dropout_prob': 0.0, 'epoc...</td>\n",
       "      <td>1798</td>\n",
       "      <td>64</td>\n",
       "      <td>0.562371</td>\n",
       "      <td>35.519339</td>\n",
       "      <td>1.149921</td>\n",
       "      <td>0.090007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>95.783653</td>\n",
       "      <td>0.956715</td>\n",
       "      <td>0.959971</td>\n",
       "      <td>0.957837</td>\n",
       "      <td>[[1856, 0, 32, 1, 0, 5], [44, 1570, 33, 20, 14...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  num_parameters  \\\n",
       "0  {'batch_size': 256, 'dropout_prob': 0.0, 'epoc...            1798   \n",
       "1  {'batch_size': 256, 'dropout_prob': 0.0, 'epoc...            1798   \n",
       "2  {'batch_size': 256, 'dropout_prob': 0.0, 'epoc...            1798   \n",
       "3  {'batch_size': 256, 'dropout_prob': 0.0, 'epoc...            1798   \n",
       "4  {'batch_size': 256, 'dropout_prob': 0.0, 'epoc...            1798   \n",
       "\n",
       "   num_epochs  epoch_train_time  training_time  backpropagation_time  \\\n",
       "0          64          0.535887      36.422380              1.194958   \n",
       "1          64          0.577678      36.345322              1.206922   \n",
       "2          64          0.664291      36.255791              1.194468   \n",
       "3          64          0.519926      35.209785              1.137281   \n",
       "4          64          0.562371      35.519339              1.149921   \n",
       "\n",
       "   loss_min  max_cpu_usage  max_ram_usage   accuracy  f1_score  precision  \\\n",
       "0  0.024936            0.0           27.4  97.606705  0.975744   0.976670   \n",
       "1  0.111199            2.4           27.3  93.986522  0.938081   0.942167   \n",
       "2  0.051083            0.0           27.3  96.250216  0.961966   0.962541   \n",
       "3  0.009414            0.0           27.3  98.729912  0.987242   0.987249   \n",
       "4  0.090007            0.0           27.4  95.783653  0.956715   0.959971   \n",
       "\n",
       "     recall                                   confusion_matrix  \n",
       "0  0.976067  [[1893, 1, 0, 0, 0, 0], [23, 1739, 15, 25, 55,...  \n",
       "1  0.939865  [[1843, 14, 23, 9, 0, 5], [38, 1467, 26, 34, 2...  \n",
       "2  0.962502  [[1868, 0, 26, 0, 0, 0], [35, 1671, 27, 13, 10...  \n",
       "3  0.987299  [[1894, 0, 0, 0, 0, 0], [11, 1859, 5, 11, 26, ...  \n",
       "4  0.957837  [[1856, 0, 32, 1, 0, 5], [44, 1570, 33, 20, 14...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_parameters</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>epoch_train_time</th>\n",
       "      <th>training_time</th>\n",
       "      <th>backpropagation_time</th>\n",
       "      <th>loss_min</th>\n",
       "      <th>max_cpu_usage</th>\n",
       "      <th>max_ram_usage</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1440.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43350.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>0.557101</td>\n",
       "      <td>69.339290</td>\n",
       "      <td>1.544119</td>\n",
       "      <td>0.232875</td>\n",
       "      <td>0.582014</td>\n",
       "      <td>30.827361</td>\n",
       "      <td>89.312042</td>\n",
       "      <td>0.880953</td>\n",
       "      <td>0.885398</td>\n",
       "      <td>0.893120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>56796.903988</td>\n",
       "      <td>32.011117</td>\n",
       "      <td>0.092571</td>\n",
       "      <td>593.382561</td>\n",
       "      <td>0.254017</td>\n",
       "      <td>0.407383</td>\n",
       "      <td>1.492135</td>\n",
       "      <td>0.573374</td>\n",
       "      <td>21.298372</td>\n",
       "      <td>0.245089</td>\n",
       "      <td>0.244977</td>\n",
       "      <td>0.212984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1798.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.377115</td>\n",
       "      <td>26.362886</td>\n",
       "      <td>1.083805</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>16.303784</td>\n",
       "      <td>0.045710</td>\n",
       "      <td>0.026581</td>\n",
       "      <td>0.163038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7174.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.481667</td>\n",
       "      <td>35.777358</td>\n",
       "      <td>1.369437</td>\n",
       "      <td>0.035784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.700000</td>\n",
       "      <td>93.839641</td>\n",
       "      <td>0.936753</td>\n",
       "      <td>0.940749</td>\n",
       "      <td>0.938396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12950.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>0.554372</td>\n",
       "      <td>52.618130</td>\n",
       "      <td>1.502501</td>\n",
       "      <td>0.085287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.800000</td>\n",
       "      <td>96.712459</td>\n",
       "      <td>0.966343</td>\n",
       "      <td>0.968198</td>\n",
       "      <td>0.967125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>43590.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>0.622369</td>\n",
       "      <td>71.405412</td>\n",
       "      <td>1.679027</td>\n",
       "      <td>0.200058</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>30.900000</td>\n",
       "      <td>98.159668</td>\n",
       "      <td>0.981273</td>\n",
       "      <td>0.981997</td>\n",
       "      <td>0.981597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>169094.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>1.107425</td>\n",
       "      <td>22558.458012</td>\n",
       "      <td>3.577647</td>\n",
       "      <td>1.786622</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>32.400000</td>\n",
       "      <td>99.628478</td>\n",
       "      <td>0.996276</td>\n",
       "      <td>0.996291</td>\n",
       "      <td>0.996285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_parameters   num_epochs  epoch_train_time  training_time  \\\n",
       "count     1440.000000  1440.000000       1440.000000    1440.000000   \n",
       "mean     43350.000000    96.000000          0.557101      69.339290   \n",
       "std      56796.903988    32.011117          0.092571     593.382561   \n",
       "min       1798.000000    64.000000          0.377115      26.362886   \n",
       "25%       7174.000000    64.000000          0.481667      35.777358   \n",
       "50%      12950.000000    96.000000          0.554372      52.618130   \n",
       "75%      43590.000000   128.000000          0.622369      71.405412   \n",
       "max     169094.000000   128.000000          1.107425   22558.458012   \n",
       "\n",
       "       backpropagation_time     loss_min  max_cpu_usage  max_ram_usage  \\\n",
       "count           1440.000000  1440.000000    1440.000000    1440.000000   \n",
       "mean               1.544119     0.232875       0.582014      30.827361   \n",
       "std                0.254017     0.407383       1.492135       0.573374   \n",
       "min                1.083805     0.000175       0.000000      27.300000   \n",
       "25%                1.369437     0.035784       0.000000      30.700000   \n",
       "50%                1.502501     0.085287       0.000000      30.800000   \n",
       "75%                1.679027     0.200058       0.800000      30.900000   \n",
       "max                3.577647     1.786622      19.000000      32.400000   \n",
       "\n",
       "          accuracy     f1_score    precision       recall  \n",
       "count  1440.000000  1440.000000  1440.000000  1440.000000  \n",
       "mean     89.312042     0.880953     0.885398     0.893120  \n",
       "std      21.298372     0.245089     0.244977     0.212984  \n",
       "min      16.303784     0.045710     0.026581     0.163038  \n",
       "25%      93.839641     0.936753     0.940749     0.938396  \n",
       "50%      96.712459     0.966343     0.968198     0.967125  \n",
       "75%      98.159668     0.981273     0.981997     0.981597  \n",
       "max      99.628478     0.996276     0.996291     0.996285  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                  1440\n",
       "unique                                                 1440\n",
       "top       {'batch_size': 256, 'dropout_prob': 0.0, 'epoc...\n",
       "freq                                                      1\n",
       "Name: params, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnig_rate_data = df['params']\n",
    "learnig_rate_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diss_3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
