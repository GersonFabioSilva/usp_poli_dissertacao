{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Inicialização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "import  torch\n",
        "import  torch.nn as nn\n",
        "import  torch.nn.functional as F\n",
        "import  torch.optim as optim\n",
        "import  psutil\n",
        "import  os\n",
        "import  time\n",
        "import  joblib\n",
        "import  warnings\n",
        "import  pandas as pd\n",
        "import  seaborn as sns\n",
        "import  snap7\n",
        "import  ctypes\n",
        "import  struct\n",
        "import  numpy as np\n",
        "import  matplotlib.pyplot as plt\n",
        "\n",
        "from    torch.utils.data import DataLoader, TensorDataset\n",
        "from    sklearn.model_selection import train_test_split\n",
        "from    sklearn.metrics import confusion_matrix, classification_report\n",
        "from    sklearn.ensemble import RandomForestClassifier\n",
        "from    sklearn.preprocessing import LabelEncoder\n",
        "from    sklearn.model_selection import GridSearchCV\n",
        "from    sklearn.preprocessing import StandardScaler\n",
        "from    sklearn.preprocessing import MinMaxScaler\n",
        "from    sklearn.model_selection import ParameterGrid\n",
        "from    snap7.type import S7DataItem, Area, WordLen\n",
        "from    snap7.util import *\n",
        "from    imblearn.over_sampling import SMOTE\n",
        "from    imblearn.under_sampling import RandomUnderSampler\n",
        "from    imblearn.pipeline import Pipeline\n",
        "from    imblearn.combine import SMOTETomek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Carregar e Preparar Conjunto de Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UDI</th>\n",
              "      <th>Product ID</th>\n",
              "      <th>Type</th>\n",
              "      <th>Air temperature [K]</th>\n",
              "      <th>Process temperature [K]</th>\n",
              "      <th>Rotational speed [rpm]</th>\n",
              "      <th>Torque [Nm]</th>\n",
              "      <th>Tool wear [min]</th>\n",
              "      <th>Target</th>\n",
              "      <th>Failure Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>M14860</td>\n",
              "      <td>M</td>\n",
              "      <td>298.1</td>\n",
              "      <td>308.6</td>\n",
              "      <td>1551</td>\n",
              "      <td>42.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>No Failure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>L47181</td>\n",
              "      <td>L</td>\n",
              "      <td>298.2</td>\n",
              "      <td>308.7</td>\n",
              "      <td>1408</td>\n",
              "      <td>46.3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>No Failure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>L47182</td>\n",
              "      <td>L</td>\n",
              "      <td>298.1</td>\n",
              "      <td>308.5</td>\n",
              "      <td>1498</td>\n",
              "      <td>49.4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>No Failure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>L47183</td>\n",
              "      <td>L</td>\n",
              "      <td>298.2</td>\n",
              "      <td>308.6</td>\n",
              "      <td>1433</td>\n",
              "      <td>39.5</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>No Failure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>L47184</td>\n",
              "      <td>L</td>\n",
              "      <td>298.2</td>\n",
              "      <td>308.7</td>\n",
              "      <td>1408</td>\n",
              "      <td>40.0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>No Failure</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   UDI Product ID Type  Air temperature [K]  Process temperature [K]  \\\n",
              "0    1     M14860    M                298.1                    308.6   \n",
              "1    2     L47181    L                298.2                    308.7   \n",
              "2    3     L47182    L                298.1                    308.5   \n",
              "3    4     L47183    L                298.2                    308.6   \n",
              "4    5     L47184    L                298.2                    308.7   \n",
              "\n",
              "   Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Target Failure Type  \n",
              "0                    1551         42.8                0       0   No Failure  \n",
              "1                    1408         46.3                3       0   No Failure  \n",
              "2                    1498         49.4                5       0   No Failure  \n",
              "3                    1433         39.5                7       0   No Failure  \n",
              "4                    1408         40.0                9       0   No Failure  "
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# dados importados da plataforma KAGGLE - https://www.kaggle.com/datasets/shivamb/machine-predictive-maintenance-classification\n",
        "df = pd.read_csv(\"predictive_maintenance.csv\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* descartar as colunas desnecessárias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "df=df.drop(['Product ID','UDI','Target'],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* codificar a coluna de falhas para tipo int entre 0 e 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"'\\n0 - 112  - heat dissipation\\n1 - 9652 - no Failure\\n2 - 78   - overstrain\\n3 - 95   - power failure\\n4 - 18   - random failure\\n5 - 45   - tool wear\\n\""
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Perform label encoding\n",
        "df['Failure Type_encoded'] = label_encoder.fit_transform(df['Failure Type'])\n",
        "\n",
        "df['Failure Type_encoded'].value_counts()\n",
        "\n",
        "''''\n",
        "0 - 112  - heat dissipation\n",
        "1 - 9652 - no Failure\n",
        "2 - 78   - overstrain\n",
        "3 - 95   - power failure\n",
        "4 - 18   - random failure\n",
        "5 - 45   - tool wear\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* converter a coluna 'Type' (string) em outras duas separadas do tipo bool (uma para cada tipo de material) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Air temperature [K]</th>\n",
              "      <th>Process temperature [K]</th>\n",
              "      <th>Rotational speed [rpm]</th>\n",
              "      <th>Torque [Nm]</th>\n",
              "      <th>Tool wear [min]</th>\n",
              "      <th>Failure Type</th>\n",
              "      <th>Failure Type_encoded</th>\n",
              "      <th>Type_L</th>\n",
              "      <th>Type_M</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>298.1</td>\n",
              "      <td>308.6</td>\n",
              "      <td>1551</td>\n",
              "      <td>42.8</td>\n",
              "      <td>0</td>\n",
              "      <td>No Failure</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>298.2</td>\n",
              "      <td>308.7</td>\n",
              "      <td>1408</td>\n",
              "      <td>46.3</td>\n",
              "      <td>3</td>\n",
              "      <td>No Failure</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>298.1</td>\n",
              "      <td>308.5</td>\n",
              "      <td>1498</td>\n",
              "      <td>49.4</td>\n",
              "      <td>5</td>\n",
              "      <td>No Failure</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>298.2</td>\n",
              "      <td>308.6</td>\n",
              "      <td>1433</td>\n",
              "      <td>39.5</td>\n",
              "      <td>7</td>\n",
              "      <td>No Failure</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>298.2</td>\n",
              "      <td>308.7</td>\n",
              "      <td>1408</td>\n",
              "      <td>40.0</td>\n",
              "      <td>9</td>\n",
              "      <td>No Failure</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Air temperature [K]  Process temperature [K]  Rotational speed [rpm]  \\\n",
              "0                298.1                    308.6                    1551   \n",
              "1                298.2                    308.7                    1408   \n",
              "2                298.1                    308.5                    1498   \n",
              "3                298.2                    308.6                    1433   \n",
              "4                298.2                    308.7                    1408   \n",
              "\n",
              "   Torque [Nm]  Tool wear [min] Failure Type  Failure Type_encoded  Type_L  \\\n",
              "0         42.8                0   No Failure                     1   False   \n",
              "1         46.3                3   No Failure                     1    True   \n",
              "2         49.4                5   No Failure                     1    True   \n",
              "3         39.5                7   No Failure                     1    True   \n",
              "4         40.0                9   No Failure                     1    True   \n",
              "\n",
              "   Type_M  \n",
              "0    True  \n",
              "1   False  \n",
              "2   False  \n",
              "3   False  \n",
              "4   False  "
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.get_dummies(df, columns=['Type'], prefix='Type', drop_first=True)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* separar os dados em: dados de entrada (features), X  e dados de saída (label), y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definição do conjunto de dados de entrada e do conjunto de dados de saída\n",
        "\n",
        "X_raw = df.drop(['Failure Type','Failure Type_encoded'], axis=1).values\n",
        "y_raw= df['Failure Type_encoded'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Em aplicações do mundo real, a modelagem de classificação frequentemente enfrenta o problema de conjuntos de dados desequilibrados, onde o número de instâncias da classe majoritária é muito maior do que o da classe minoritária, o que dificulta o aprendizado adequado do modelo em relação à classe minoritária. Isso se torna um problema sério quando a informação contida na classe minoritária é mais importante como, por exemplo, no conjunto utilizado.\n",
        "\n",
        "* Uma das abordagens populares para resolver o problema de conjuntos de dados desequilibrados é a superamostragem da classe minoritária ou a subamostragem da classe majoritária. No entanto, essas abordagens possuem suas próprias limitações. No método tradicional de superamostragem, a ideia é duplicar aleatoriamente alguns exemplos da classe minoritária — essa técnica não adiciona novas informações ao conjunto de dados. Por outro lado, o método de subamostragem é realizado removendo aleatoriamente alguns exemplos da classe majoritária, o que resulta na perda de algumas informações originais dos dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Total de amostras antes balanceamento:',df['Failure Type_encoded'].count())\n",
        "print('Total de amostras por falha:\\n\\n', df['Failure Type_encoded'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Contar a quantidade de ocorrências por evento de falha\n",
        "\n",
        "class_counts  = df['Failure Type_encoded'].value_counts()\n",
        "\n",
        "class_mapping = {\n",
        "    0: 'dissipação de calor',\n",
        "    1: 'sem falha',\n",
        "    2: 'sobrecarga',\n",
        "    3: 'potência',\n",
        "    4: 'aleatória',\n",
        "    5: 'desgaste ferramenta'\n",
        "}\n",
        "\n",
        "\n",
        "# Substituir os valores codificados pelos nomes das classes\n",
        "class_counts.index = class_counts.index.map(class_mapping)\n",
        "\n",
        "# Plotar a visualização\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(class_counts.index, class_counts.values, color='lightgray')\n",
        "\n",
        "# Adicionar os rótulos (quantidades) em cima de cada barra\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval, int(yval), \n",
        "             ha='center', va='bottom')  # centraliza o texto\n",
        "\n",
        "plt.xlabel('Tipo de Falha')\n",
        "plt.ylabel('Ocorrências')\n",
        "plt.title('Distribuição das Ocorrências de Falha')\n",
        "plt.xticks(rotation=45)  # Para manter as etiquetas no eixo X horizontais\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Uma solução para superar essas limitações é gerar novos exemplos sintetizados a partir da classe minoritária existente. Esse método é conhecido como Técnica de Superamostragem da Minoria Sintética (SMOTE). Existem muitas variações do SMOTE, mas neste artigo será explicado o método SMOTE-Tomek Links e sua implementação em Python. Esse método combina a superamostragem do SMOTE com a subamostragem dos Tomek Links.\n",
        "\n",
        "* O método SMOTE-Tomek Links, desenvolvido por Chawla et al. (2002) é uma combinação de técnicas que visa equilibrar os dados ao aumentar a representatividade da classe minoritária através da criação de novos exemplos sintéticos e ao mesmo tempo remover exemplos que são considerados ruidosos ou redundantes na classe majoritária. A implementação desta abordagem utilizando Python é apresentada, detalhando os passos e a lógica do algoritmo, assim como os resultados obtidos em diferentes conjuntos de dados desequilibrados.\n",
        "\n",
        "* A combinação das técnicas de superamostragem e subamostragem, especificamente utilizando o método SMOTE-Tomek Links, mostra-se eficaz na melhoria do desempenho dos modelos de classificação em conjuntos de dados desequilibrados. Esta abordagem permite ao modelo aprender de forma mais eficiente a partir da classe minoritária, mantendo a integridade e a diversidade da informação no conjunto de dados.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#implementação do método SMOTE no conunto de dados\n",
        "smt=SMOTETomek(sampling_strategy='auto',random_state=42)\n",
        "X_resampled, y_resampled = smt.fit_resample(X_raw, y_raw)\n",
        "\n",
        "# Convertendo para dataframe do pandas\n",
        "df_resampled = pd.DataFrame(X_resampled, columns=[f'feature_{i}' for i in range(X_resampled.shape[1])])\n",
        "df_resampled['Type_encoded'] = y_resampled \n",
        "\n",
        "df_resampled.head()\n",
        "\n",
        "#distribuição das classes após balanceamento\n",
        "print('Total de amostras após balanceamento:',df_resampled['Type_encoded'].count())\n",
        "print('Total de amostras por falha:\\n\\n', df_resampled['Type_encoded'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_counts  = df_resampled['Type_encoded'].value_counts()\n",
        "\n",
        "class_mapping = {\n",
        "    0: 'dissipação de calor',\n",
        "    1: 'sem falha',\n",
        "    2: 'sobrecarga',\n",
        "    3: 'potência',\n",
        "    4: 'aleatória',\n",
        "    5: 'desgaste ferramenta'\n",
        "}\n",
        "\n",
        "\n",
        "# Substituir os valores codificados pelos nomes das classes\n",
        "class_counts.index = class_counts.index.map(class_mapping)\n",
        "\n",
        "# Plotar a visualização\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(class_counts.index, class_counts.values, color='lightgray')\n",
        "\n",
        "# Adicionar os rótulos (quantidades) em cima de cada barra\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval, int(yval), \n",
        "             ha='center', va='bottom')  # centraliza o texto\n",
        "\n",
        "plt.xlabel('Tipo de Falha')\n",
        "plt.ylabel('Ocorrências')\n",
        "plt.title('Distribuição das Ocorrências de Falha')\n",
        "plt.xticks(rotation=45)  # Para manter as etiquetas no eixo X horizontais\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Temp_Ar</th>\n",
              "      <th>Temp_Pr</th>\n",
              "      <th>Vel_Spindle</th>\n",
              "      <th>Torque</th>\n",
              "      <th>Desg_Ferr</th>\n",
              "      <th>Mat_L</th>\n",
              "      <th>Mat_M</th>\n",
              "      <th>Tipo_Falha</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>298.1</td>\n",
              "      <td>308.6</td>\n",
              "      <td>1551.0</td>\n",
              "      <td>42.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>298.2</td>\n",
              "      <td>308.7</td>\n",
              "      <td>1408.0</td>\n",
              "      <td>46.3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>298.1</td>\n",
              "      <td>308.5</td>\n",
              "      <td>1498.0</td>\n",
              "      <td>49.4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>298.2</td>\n",
              "      <td>308.6</td>\n",
              "      <td>1433.0</td>\n",
              "      <td>39.5</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>298.2</td>\n",
              "      <td>308.7</td>\n",
              "      <td>1408.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Temp_Ar  Temp_Pr  Vel_Spindle  Torque  Desg_Ferr  Mat_L  Mat_M  Tipo_Falha\n",
              "0    298.1    308.6       1551.0    42.8        0.0    0.0    1.0           1\n",
              "1    298.2    308.7       1408.0    46.3        3.0    1.0    0.0           1\n",
              "2    298.1    308.5       1498.0    49.4        5.0    1.0    0.0           1\n",
              "3    298.2    308.6       1433.0    39.5        7.0    1.0    0.0           1\n",
              "4    298.2    308.7       1408.0    40.0        9.0    1.0    0.0           1"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_resampled = df_resampled.rename(columns={'feature_0':'Temp_Ar'})\n",
        "df_resampled = df_resampled.rename(columns={'feature_1':'Temp_Pr'})\n",
        "df_resampled = df_resampled.rename(columns={'feature_2':'Vel_Spindle'})\n",
        "df_resampled = df_resampled.rename(columns={'feature_3':'Torque'})\n",
        "df_resampled = df_resampled.rename(columns={'feature_4':'Desg_Ferr'})\n",
        "df_resampled = df_resampled.rename(columns={'feature_5':'Mat_L'})\n",
        "df_resampled = df_resampled.rename(columns={'feature_6':'Mat_M'})\n",
        "\n",
        "df_resampled = df_resampled.rename(columns={'Type_encoded':'Tipo_Falha'})\n",
        "\n",
        "df_resampled.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Metodo para normalização do conjunto de dados e formatação para as diferentes redes neurais (MLP e KAN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Temp_Ar  Temp_Pr  Vel_Spindle  Torque  Desg_Ferr  Mat_L  Mat_M\n",
            "0    298.1    308.6       1551.0    42.8        0.0    0.0    1.0\n",
            "1    298.2    308.7       1408.0    46.3        3.0    1.0    0.0\n",
            "2    298.1    308.5       1498.0    49.4        5.0    1.0    0.0\n",
            "3    298.2    308.6       1433.0    39.5        7.0    1.0    0.0\n",
            "4    298.2    308.7       1408.0    40.0        9.0    1.0    0.0\n",
            "              0         1         2         3         4         5         6\n",
            "0      0.304348  0.358025  0.222934  0.535714  0.000000  0.000000  1.000000\n",
            "1      0.315217  0.370370  0.139697  0.583791  0.011858  1.000000  0.000000\n",
            "2      0.304348  0.345679  0.192084  0.626374  0.019763  1.000000  0.000000\n",
            "3      0.315217  0.358025  0.154249  0.490385  0.027668  1.000000  0.000000\n",
            "4      0.315217  0.370370  0.139697  0.497253  0.035573  1.000000  0.000000\n",
            "...         ...       ...       ...       ...       ...       ...       ...\n",
            "57863  0.329237  0.454055  0.121901  0.580603  0.804303  1.000000  0.000000\n",
            "57864  0.922588  0.913064  0.147489  0.604905  0.850436  0.000000  1.000000\n",
            "57865  0.552975  0.526194  0.229077  0.470219  0.836284  0.697473  0.000000\n",
            "57866  0.690035  0.710277  0.214813  0.442483  0.820605  0.693514  0.306486\n",
            "57867  0.598892  0.605268  0.238016  0.468541  0.896775  1.000000  0.000000\n",
            "\n",
            "[57868 rows x 7 columns]\n"
          ]
        }
      ],
      "source": [
        "def load_Preditive_Maintenance_Dataset():\n",
        "\n",
        "    X_ = df_resampled.drop(['Tipo_Falha'], axis=\"columns\") \n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    X_   = scaler.fit_transform(X_)    \n",
        "    joblib.dump(scaler, 'minmax_scaler.pkl')  \n",
        "\n",
        "    data_min = scaler.data_min_\n",
        "    data_max = scaler.data_max_\n",
        "    feature_range_min, feature_range_max = scaler.feature_range  \n",
        "    \n",
        "    y_ = df_resampled['Tipo_Falha']\n",
        "\n",
        "    #convertendo os dados em tensores e atribuindo a sua execucção na CPU ou GPU (device) conforme disponibilidade avaliada no inicio do programa\n",
        "    X = torch.tensor(X_, dtype = torch.float32).to(device)\n",
        "    y = torch.tensor(y_.values, dtype = torch.long).to(device)  \n",
        "    \n",
        "    #separa os dados entre conjunto de dados para treinamento (80%) e conjunto de dados para teste/validação (20% <-> teste_size=0.2)\n",
        "    train_data_, test_data_, train_target_, test_target_ = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # geração de  mini batches para melhorar desempenho do treinamento\n",
        "    train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_data_, train_target_), batch_size=10, shuffle=True)   \n",
        "    validation_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_data_, test_target_), batch_size=10, shuffle=False)  \n",
        "\n",
        "    #conjunto de dados no formato a ser utilizado no redes MLP\n",
        "    train_data_loader   = train_loader\n",
        "    test_data_loader    = validation_loader\n",
        "\n",
        "    train_data      = train_data_    \n",
        "    test_data       = test_data_\n",
        "    train_labels    = train_target_\n",
        "    test_label      = test_target_\n",
        "    data_min_scaler = data_min\n",
        "    data_max_scaler = data_max\n",
        "    feature_range_min_scaler = feature_range_min\n",
        "    feature_range_max_scaler = feature_range_max\n",
        "\n",
        "    MLP_dataset     = [train_data,\n",
        "                        train_labels,\n",
        "                        test_data,\n",
        "                        test_label,\n",
        "                        train_data_loader,\n",
        "                        test_data_loader,\n",
        "                        data_min_scaler,\n",
        "                        data_max_scaler,\n",
        "                        feature_range_min_scaler,\n",
        "                        feature_range_max_scaler ]  \n",
        "\n",
        "    return MLP_dataset\n",
        "\n",
        "dataset =load_Preditive_Maintenance_Dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Implementação Rede Neural Multilayer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class MLP_Model(nn.Module):  \n",
        "    def __init__(self, layer_sizes, dropout_prob=0.0):\n",
        "        super(MLP_Model, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.dropouts = nn.ModuleList()\n",
        "        \n",
        "        for i in range(len(layer_sizes) - 1):\n",
        "            self.layers.append(nn.Linear(layer_sizes[i], layer_sizes[i + 1]))\n",
        "            if i < len(layer_sizes) - 2:  # No dropout after the last layer\n",
        "                self.dropouts.append(nn.Dropout(p=dropout_prob))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        for i in range(len(self.layers) - 1):\n",
        "            x = F.relu(self.layers[i](x))\n",
        "            x = self.dropouts[i](x)\n",
        "        x = self.layers[-1](x)\n",
        "        return x\n",
        "\n",
        "def initialize_weights(model):\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, nn.Linear):\n",
        "            nn.init.kaiming_normal_(layer.weight)\n",
        "            if layer.bias is not None:\n",
        "                nn.init.zeros_(layer.bias)\n",
        "\n",
        "def extract_weights_biases(model):\n",
        "    weights_and_biases = {}\n",
        "    for i, layer in enumerate(model.layers):\n",
        "        if isinstance(layer, nn.Linear):\n",
        "            weights_and_biases[f'layer_{i}_weights'] = layer.weight.data.cpu().numpy()\n",
        "            weights_and_biases[f'layer_{i}_biases'] = layer.bias.data.cpu().numpy()\n",
        "    return weights_and_biases\n",
        "\n",
        "\n",
        "def train(model, train_loader, criterion, optimizer, num_epochs, device):\n",
        "    model.train()\n",
        "\n",
        "    ram_usage       = []\n",
        "    cpu_usage       = []\n",
        "    backprop_time   = []\n",
        "    loss_list       = []\n",
        "\n",
        "    startMLP_train = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            startMLP_bwd = time.time()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            endMLP_bwd = time.time()\n",
        "            backprop_time.append((endMLP_bwd - startMLP_bwd) * 1000)\n",
        "\n",
        "        loss_list.append(loss.item())\n",
        "        ram_usage.append(psutil.virtual_memory().percent)\n",
        "        cpu_usage.append(psutil.cpu_percent(interval=1))\n",
        "        print(f'Epoch {epoch+1}/{num_epochs} | Loss: {round(loss.item(), 4)} | Backpropagation Time: {round(backprop_time[-1], 2)} ms | CPU Usage: {round(cpu_usage[-1], 2)} % | RAM Usage: {round(ram_usage[-1], 2)} %', end=\"\\r\")\n",
        "\n",
        "    endMLP_train = time.time()\n",
        "\n",
        "    weights_and_biases = extract_weights_biases(model)\n",
        "\n",
        "    train_time = endMLP_train - startMLP_train\n",
        "    backpropagation_time = np.mean(backprop_time)\n",
        "    max_cpu_usage = np.max(cpu_usage)   \n",
        "    max_ram_usage = np.max(ram_usage)\n",
        "\n",
        "    info = {\n",
        "        'Num_Epochs'            : num_epochs,\n",
        "        'Back_Propagation_Time' : backpropagation_time,\n",
        "        'Max_CPU_usage'         : max_cpu_usage,\n",
        "        'Max_RAM_usage'         : max_ram_usage,\n",
        "        'Train_Time'            : train_time,\n",
        "        'Loss_List'             : loss_list,\n",
        "        'Weights_Bias'          : weights_and_biases\n",
        "    }\n",
        "\n",
        "    return info\n",
        "\n",
        "def test_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "layers = [7,128,64,32,6] \n",
        "model = MLP_Model(layers).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
        "\n",
        "num_params = count_parameters(model)\n",
        "print(f'Número total de parâmetros treináveis: {num_params}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlp_train_results = train(model, dataset[4], criterion, optimizer, num_epochs=2, device='cuda')\n",
        "\n",
        "test_model(model, dataset[5],device='cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preparação dos dados dos pesos e vieses para envio para o CLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def format_data_for_db(weights_and_biases):\n",
        "    formatted_data = {}\n",
        "    for name, data in weights_and_biases.items():\n",
        "        formatted_data[name] = []\n",
        "        for value in data.flatten():\n",
        "            formatted_data[name].append(struct.pack('>f', value))\n",
        "    return formatted_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(mlp_train_results['Weights_Bias'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "formatted_data = format_data_for_db(mlp_train_results['Weights_Bias'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def connect_to_plc(plc_ip, rack, slot):\n",
        "    client = snap7.client.Client()\n",
        "    client.connect(plc_ip, rack, slot)\n",
        "    return client\n",
        "\n",
        "# Função para escrever dados no DB\n",
        "def write_data_to_db(client, db_number, start_offset, data):\n",
        "    for offset, value in enumerate(data):\n",
        "        client.db_write(db_number, start_offset + offset * 4, value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "PLC_IP = '192.168.0.1'  # IP do PLC\n",
        "RACK = 0\n",
        "SLOT = 1\n",
        "DB_NUMBER = 19005  # Número do Data Block\n",
        "\n",
        "client = connect_to_plc(PLC_IP, RACK, SLOT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Offsets para cada camada\n",
        "offsets = {\n",
        "    'layer_0_weights'   : 0,\n",
        "    'layer_0_biases'    : 3584,\n",
        "    'layer_1_weights'   : 4096,\n",
        "    'layer_1_biases'    : 36864,\n",
        "    'layer_2_weights'   : 37120,\n",
        "    'layer_2_biases'    : 45312,\n",
        "    'layer_3_weights'   : 45440,\n",
        "    'layer_3_biases'    : 46208\n",
        "}\n",
        "\n",
        "for name, data in formatted_data.items():\n",
        "    write_data_to_db(client, DB_NUMBER, offsets[name], data)\n",
        "\n",
        "client.disconnect()\n",
        "client.destroy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Previsão de falha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "7RE1svm9cXkX",
        "D7ERosp1iM17",
        "CBD58aME1Rvd",
        "tbhg0iWQ1FX-"
      ],
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
