{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Inicialização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'moviepy'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m  \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m  \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m  \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mImageSequenceClip\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m  \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m    \u001b[38;5;21;01mkan\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'moviepy'"
          ]
        }
      ],
      "source": [
        "import  torch\n",
        "import  torch.nn as nn\n",
        "import  torch.nn.functional as F\n",
        "import  torch.optim as optim\n",
        "import  psutil\n",
        "import  os\n",
        "import joblib\n",
        "import  warnings\n",
        "import  pandas as pd\n",
        "import  seaborn as sns\n",
        "import  numpy as np\n",
        "import  matplotlib.pyplot as plt\n",
        "import  moviepy.video.io.ImageSequenceClip\n",
        "import  time\n",
        "from    kan import *\n",
        "from    sklearn.model_selection import train_test_split\n",
        "from    sklearn.metrics import confusion_matrix, classification_report\n",
        "from    sklearn.ensemble import RandomForestClassifier\n",
        "from    sklearn.preprocessing import LabelEncoder\n",
        "from    sklearn.model_selection import GridSearchCV\n",
        "from    sklearn.preprocessing import StandardScaler\n",
        "from    sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from    imblearn.over_sampling import SMOTE\n",
        "from    imblearn.under_sampling import RandomUnderSampler\n",
        "from    imblearn.pipeline import Pipeline\n",
        "from    imblearn.combine import SMOTETomek\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Carregar e Preparar Conjunto de Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UDI</th>\n",
              "      <th>Product ID</th>\n",
              "      <th>Type</th>\n",
              "      <th>Air temperature [K]</th>\n",
              "      <th>Process temperature [K]</th>\n",
              "      <th>Rotational speed [rpm]</th>\n",
              "      <th>Torque [Nm]</th>\n",
              "      <th>Tool wear [min]</th>\n",
              "      <th>Target</th>\n",
              "      <th>Failure Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>M14860</td>\n",
              "      <td>M</td>\n",
              "      <td>298.1</td>\n",
              "      <td>308.6</td>\n",
              "      <td>1551</td>\n",
              "      <td>42.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>No Failure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>L47181</td>\n",
              "      <td>L</td>\n",
              "      <td>298.2</td>\n",
              "      <td>308.7</td>\n",
              "      <td>1408</td>\n",
              "      <td>46.3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>No Failure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>L47182</td>\n",
              "      <td>L</td>\n",
              "      <td>298.1</td>\n",
              "      <td>308.5</td>\n",
              "      <td>1498</td>\n",
              "      <td>49.4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>No Failure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>L47183</td>\n",
              "      <td>L</td>\n",
              "      <td>298.2</td>\n",
              "      <td>308.6</td>\n",
              "      <td>1433</td>\n",
              "      <td>39.5</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>No Failure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>L47184</td>\n",
              "      <td>L</td>\n",
              "      <td>298.2</td>\n",
              "      <td>308.7</td>\n",
              "      <td>1408</td>\n",
              "      <td>40.0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>No Failure</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   UDI Product ID Type  Air temperature [K]  Process temperature [K]  \\\n",
              "0    1     M14860    M                298.1                    308.6   \n",
              "1    2     L47181    L                298.2                    308.7   \n",
              "2    3     L47182    L                298.1                    308.5   \n",
              "3    4     L47183    L                298.2                    308.6   \n",
              "4    5     L47184    L                298.2                    308.7   \n",
              "\n",
              "   Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Target Failure Type  \n",
              "0                    1551         42.8                0       0   No Failure  \n",
              "1                    1408         46.3                3       0   No Failure  \n",
              "2                    1498         49.4                5       0   No Failure  \n",
              "3                    1433         39.5                7       0   No Failure  \n",
              "4                    1408         40.0                9       0   No Failure  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# dados importados da plataforma KAGGLE - https://www.kaggle.com/datasets/shivamb/machine-predictive-maintenance-classification\n",
        "df = pd.read_csv(\"predictive_maintenance.csv\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* descartar as colunas desnecessárias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df=df.drop(['Product ID','UDI','Target'],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* codificar a coluna de falhas para tipo int entre 0 e 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Failure Type_encoded\n",
              "1    9652\n",
              "0     112\n",
              "3      95\n",
              "2      78\n",
              "5      45\n",
              "4      18\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Perform label encoding\n",
        "df['Failure Type_encoded'] = label_encoder.fit_transform(df['Failure Type'])\n",
        "\n",
        "df['Failure Type_encoded'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* converter a coluna 'Type' (string) em outras duas separadas do tipo bool (uma para cada tipo de material) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(\u001b[43mdf\u001b[49m, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m'\u001b[39m], prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m'\u001b[39m, drop_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "df = pd.get_dummies(df, columns=['Type'], prefix='Type', drop_first=True)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* separar os dados em: dados de entrada (features), X  e dados de saída (label), y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definição do conjunto de dados de entrada e do conjunto de dados de saída\n",
        "\n",
        "X_raw = df.drop(['Failure Type','Failure Type_encoded'], axis=1).values\n",
        "y_raw= df['Failure Type_encoded'].values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Em aplicações do mundo real, a modelagem de classificação frequentemente enfrenta o problema de conjuntos de dados desequilibrados, onde o número de instâncias da classe majoritária é muito maior do que o da classe minoritária, o que dificulta o aprendizado adequado do modelo em relação à classe minoritária. Isso se torna um problema sério quando a informação contida na classe minoritária é mais importante como, por exemplo, no conjunto utilizado.\n",
        "\n",
        "* Uma das abordagens populares para resolver o problema de conjuntos de dados desequilibrados é a superamostragem da classe minoritária ou a subamostragem da classe majoritária. No entanto, essas abordagens possuem suas próprias limitações. No método tradicional de superamostragem, a ideia é duplicar aleatoriamente alguns exemplos da classe minoritária — essa técnica não adiciona novas informações ao conjunto de dados. Por outro lado, o método de subamostragem é realizado removendo aleatoriamente alguns exemplos da classe majoritária, o que resulta na perda de algumas informações originais dos dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de amostras antes balanceamento: 10000\n",
            "Total de amostras por falha:\n",
            "\n",
            " Failure Type_encoded\n",
            "1    9652\n",
            "0     112\n",
            "3      95\n",
            "2      78\n",
            "5      45\n",
            "4      18\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print('Total de amostras antes balanceamento:',df['Failure Type_encoded'].count())\n",
        "print('Total de amostras por falha:\\n\\n', df['Failure Type_encoded'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Uma solução para superar essas limitações é gerar novos exemplos sintetizados a partir da classe minoritária existente. Esse método é conhecido como Técnica de Superamostragem da Minoria Sintética (SMOTE). Existem muitas variações do SMOTE, mas neste artigo será explicado o método SMOTE-Tomek Links e sua implementação em Python. Esse método combina a superamostragem do SMOTE com a subamostragem dos Tomek Links.\n",
        "\n",
        "* O método SMOTE-Tomek Links, desenvolvido por Chawla et al. (2002) é uma combinação de técnicas que visa equilibrar os dados ao aumentar a representatividade da classe minoritária através da criação de novos exemplos sintéticos e ao mesmo tempo remover exemplos que são considerados ruidosos ou redundantes na classe majoritária. A implementação desta abordagem utilizando Python é apresentada, detalhando os passos e a lógica do algoritmo, assim como os resultados obtidos em diferentes conjuntos de dados desequilibrados.\n",
        "\n",
        "* A combinação das técnicas de superamostragem e subamostragem, especificamente utilizando o método SMOTE-Tomek Links, mostra-se eficaz na melhoria do desempenho dos modelos de classificação em conjuntos de dados desequilibrados. Esta abordagem permite ao modelo aprender de forma mais eficiente a partir da classe minoritária, mantendo a integridade e a diversidade da informação no conjunto de dados.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de amostras após balanceamento: 57868\n",
            "Total de amostras por falha:\n",
            "\n",
            " Type_encoded\n",
            "2    9652\n",
            "0    9649\n",
            "5    9647\n",
            "3    9645\n",
            "4    9645\n",
            "1    9630\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#implementação do método SMOTE no conunto de dados\n",
        "smt=SMOTETomek(sampling_strategy='auto',random_state=42)\n",
        "X_resampled, y_resampled = smt.fit_resample(X_raw, y_raw)\n",
        "\n",
        "# Convertendo para dataframe do pandas\n",
        "df_resampled = pd.DataFrame(X_resampled, columns=[f'feature_{i}' for i in range(X_resampled.shape[1])])\n",
        "df_resampled['Type_encoded'] = y_resampled \n",
        "\n",
        "df_resampled.head()\n",
        "\n",
        "#distribuição das classes após balanceamento\n",
        "print('Total de amostras após balanceamento:',df_resampled['Type_encoded'].count())\n",
        "print('Total de amostras por falha:\\n\\n', df_resampled['Type_encoded'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Temp_Ar</th>\n",
              "      <th>Temp_Pr</th>\n",
              "      <th>Vel_Spindle</th>\n",
              "      <th>Torque</th>\n",
              "      <th>Desg_Ferr</th>\n",
              "      <th>Mat_L</th>\n",
              "      <th>Mat_M</th>\n",
              "      <th>Tipo_Falha</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>298.1</td>\n",
              "      <td>308.6</td>\n",
              "      <td>1551.0</td>\n",
              "      <td>42.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>298.2</td>\n",
              "      <td>308.7</td>\n",
              "      <td>1408.0</td>\n",
              "      <td>46.3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>298.1</td>\n",
              "      <td>308.5</td>\n",
              "      <td>1498.0</td>\n",
              "      <td>49.4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>298.2</td>\n",
              "      <td>308.6</td>\n",
              "      <td>1433.0</td>\n",
              "      <td>39.5</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>298.2</td>\n",
              "      <td>308.7</td>\n",
              "      <td>1408.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Temp_Ar  Temp_Pr  Vel_Spindle  Torque  Desg_Ferr  Mat_L  Mat_M  Tipo_Falha\n",
              "0    298.1    308.6       1551.0    42.8        0.0    0.0    1.0           1\n",
              "1    298.2    308.7       1408.0    46.3        3.0    1.0    0.0           1\n",
              "2    298.1    308.5       1498.0    49.4        5.0    1.0    0.0           1\n",
              "3    298.2    308.6       1433.0    39.5        7.0    1.0    0.0           1\n",
              "4    298.2    308.7       1408.0    40.0        9.0    1.0    0.0           1"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_resampled = df_resampled.rename(columns={'feature_0':'Temp_Ar'})\n",
        "df_resampled = df_resampled.rename(columns={'feature_1':'Temp_Pr'})\n",
        "df_resampled = df_resampled.rename(columns={'feature_2':'Vel_Spindle'})\n",
        "df_resampled = df_resampled.rename(columns={'feature_3':'Torque'})\n",
        "df_resampled = df_resampled.rename(columns={'feature_4':'Desg_Ferr'})\n",
        "df_resampled = df_resampled.rename(columns={'feature_5':'Mat_L'})\n",
        "df_resampled = df_resampled.rename(columns={'feature_6':'Mat_M'})\n",
        "\n",
        "df_resampled = df_resampled.rename(columns={'Type_encoded':'Tipo_Falha'})\n",
        "\n",
        "df_resampled.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Metodo para normalização do conjunto de dados e formatação para as diferentes redes neurais (MLP e KAN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df_resampled' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 50\u001b[0m\n\u001b[1;32m     45\u001b[0m     KAN_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_label\u001b[39m\u001b[38;5;124m'\u001b[39m]   \u001b[38;5;241m=\u001b[39m test_labels\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m MLP_dataset, KAN_dataset\n\u001b[0;32m---> 50\u001b[0m dataset \u001b[38;5;241m=\u001b[39m\u001b[43mload_Preditive_Maintenance_Dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[1], line 3\u001b[0m, in \u001b[0;36mload_Preditive_Maintenance_Dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_Preditive_Maintenance_Dataset\u001b[39m():\n\u001b[0;32m----> 3\u001b[0m     X_ \u001b[38;5;241m=\u001b[39m \u001b[43mdf_resampled\u001b[49m\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTipo_Falha\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''''\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    scaler = MinMaxScaler(feature_range=(-1, 1))\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    X_   = scaler.fit_transform(X_)    \u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    joblib.dump(scaler, 'minmax_scaler.pkl')\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     y_ \u001b[38;5;241m=\u001b[39m df_resampled[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTipo_Falha\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_resampled' is not defined"
          ]
        }
      ],
      "source": [
        "def load_Preditive_Maintenance_Dataset():\n",
        "\n",
        "    X_ = df_resampled.drop(['Tipo_Falha'], axis=\"columns\")\n",
        "    '''''\n",
        "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "    X_   = scaler.fit_transform(X_)    \n",
        "    joblib.dump(scaler, 'minmax_scaler.pkl')\n",
        "    '''\n",
        "    y_ = df_resampled['Tipo_Falha']\n",
        "\n",
        "    #convertendo os dados em tensores e atribuindo a sua excucção na CPU ou GPU (device) conforme disponibilidade avaliada no inicio do programa\n",
        "    X = torch.tensor(X_, dtype = torch.float32).to(device)\n",
        "    y = torch.tensor(y_.values, dtype = torch.long).to(device)    \n",
        "\n",
        "    #separa os dados entre conjunto de dados para treinamento (80%) e conjunto de dados para teste/validação (20% <-> teste_size=0.2)\n",
        "    train_data, test_data, train_target, test_target = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # geração de  mini batches para melhorar desempenho do treinamento\n",
        "    train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_data, train_target), batch_size=10, shuffle=True)   \n",
        "    validation_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_data, test_target), batch_size=10, shuffle=False)  \n",
        "\n",
        "    #conjunto de dados no formato a ser utilizado no redes MLP\n",
        "    train_data    = train_loader\n",
        "    test_data     = validation_loader\n",
        "    MLP_dataset   = [train_data, test_data]  \n",
        "\n",
        "    # conjunto de dados no formato a ser utilizado  redes KAN\n",
        "    train_inputs = torch.empty(0, 7, device=device)\n",
        "    train_labels = torch.empty(0, dtype=torch.long, device=device)\n",
        "    test_inputs = torch.empty(0, 7, device=device)\n",
        "    test_labels = torch.empty(0, dtype=torch.long, device=device)\n",
        "\n",
        "    for data, labels in train_loader:\n",
        "        train_inputs = torch.cat((train_inputs, data.to(device)), dim=0)\n",
        "        train_labels = torch.cat((train_labels, labels.to(device)), dim=0)\n",
        "\n",
        "    for data, labels in validation_loader:\n",
        "        test_inputs = torch.cat((test_inputs, data.to(device)), dim=0)\n",
        "        test_labels = torch.cat((test_labels, labels.to(device)), dim=0)\n",
        "\n",
        "    KAN_dataset = {}\n",
        "    KAN_dataset['train_input']  = train_inputs\n",
        "    KAN_dataset['test_input']   = test_inputs\n",
        "    KAN_dataset['train_label']  = train_labels\n",
        "    KAN_dataset['test_label']   = test_labels\n",
        "\n",
        "\n",
        "    return MLP_dataset, KAN_dataset\n",
        "\n",
        "dataset =load_Preditive_Maintenance_Dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Implementação Rede Kolmogorov-Arnold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'KAN' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m image_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideos\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m in_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mKAN\u001b[49m(width\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m], grid\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m      7\u001b[0m model(dataset[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_input\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mplot(beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, in_vars\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mta\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mml\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmm\u001b[39m\u001b[38;5;124m'\u001b[39m], out_vars\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m01\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m02\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m03\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m04\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m05\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m06\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'KAN' is not defined"
          ]
        }
      ],
      "source": [
        "image_folder = 'videos'\n",
        "\n",
        "in_layer = 7\n",
        "\n",
        "model = KAN(width=[7, 5, 6], grid=5, k=5, seed=0, device=device)\n",
        "\n",
        "model(dataset[1]['train_input'])\n",
        "\n",
        "model.plot(beta=100, scale=1, in_vars=['ta', 'tp', 'vs', 'to','df','ml','mm'], out_vars=['01', '02', '03','04','05','06'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "train loss: 2.25e+00 | test loss: 3.71e+00 | reg: 1.16e+02 : 100%|████| 2/2 [00:15<00:00,  7.59s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.12375254184007645, 0.13150164484977722)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def train_acc():\n",
        "    return torch.mean((torch.argmax(model(dataset[1]['train_input']), dim=1) == dataset[1]['train_label']).float())\n",
        "\n",
        "def test_acc():\n",
        "    return torch.mean((torch.argmax(model(dataset[1]['test_input']), dim=1) == dataset[1]['test_label']).float())\n",
        "\n",
        "KAN_start_train = time.time()\n",
        "\n",
        "results = model.train(dataset[1], opt=\"Adam\", device=device, metrics=(train_acc, test_acc),\n",
        "                      loss_fn=torch.nn.CrossEntropyLoss(), steps=1, lamb=0.01, lamb_entropy=10., save_fig=True, img_folder=image_folder)\n",
        "KAN_end_train = time.time()\n",
        "\n",
        "KAN_training_time = KAN_end_train - KAN_start_train\n",
        "\n",
        "results['train_acc'][-1], results['test_acc'][-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loss_evolution = np.array([x.item() for x in results['train_loss']])  \n",
        "test_loss_evolution  = np.array([x.item() for x in results['test_loss']])  \n",
        "iteration =  range(1, 20+1)       \n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(iteration, train_loss_evolution, marker='o', linestyle='-',  color='b', label='Erro Treino 1')\n",
        "plt.plot(iteration, test_loss_evolution,  marker='x', linestyle='--', color='c', label='Erro Teste 2')\n",
        "\n",
        "plt.title('Evolução do Ajuste do Erro')\n",
        "plt.xlabel('Iterações')\n",
        "plt.ylabel('Erro')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.plot(scale=1, in_vars=['ta', 'tp', 'vs', 'to','df','ml','mm'], out_vars=['01', '02', '03','04','05','06'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Building video video.mp4.\n",
            "Moviepy - Writing video video.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready video.mp4\n"
          ]
        }
      ],
      "source": [
        "video_name='video'\n",
        "fps=10\n",
        "\n",
        "fps = fps\n",
        "files = os.listdir(image_folder)\n",
        "train_index = []\n",
        "for file in files:\n",
        "    if file[0].isdigit() and file.endswith('.jpg'):\n",
        "        train_index.append(int(file[:-4]))\n",
        "\n",
        "train_index = np.sort(train_index)\n",
        "\n",
        "image_files = [image_folder+'/'+str(train_index[index])+'.jpg' for index in train_index]\n",
        "\n",
        "clip = moviepy.video.io.ImageSequenceClip.ImageSequenceClip(image_files, fps=fps)\n",
        "clip.write_videofile(video_name+'.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = model.prune()\n",
        "model(dataset[1]['train_input'])\n",
        "model.plot(scale=1, in_vars=['f1', 'f2', 'f3', 'f4','f5','f6','f7'], out_vars=['01', '02', '03','04','05','06'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "train loss: 1.40e+00 | test loss: 3.11e+00 | reg: 1.07e+02 : 100%|████| 1/1 [00:04<00:00,  4.39s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.3195662498474121, 0.3209780752658844)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# fine tune\n",
        "results_1 = model.train(dataset[1], opt=\"Adam\", device=device, metrics=(train_acc, test_acc),\n",
        "                      loss_fn=torch.nn.CrossEntropyLoss(), steps=1, lamb=0.01, lamb_entropy=10.)\n",
        "results_1['train_acc'][-1], results_1['test_acc'][-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.plot(scale=1, in_vars=['f1', 'f2', 'f3', 'f4','f5','f6','f7'], out_vars=['01', '02', '03','04','05','06'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Implementação Rede Neural Multilayer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MLP_Model(nn.Module):  \n",
        "    \n",
        "    def __init__(self):\n",
        "        super(MLP_Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(7,10)  \n",
        "        self.fc2 = nn.Linear(10,10)\n",
        "        self.fc3 = nn.Linear(10,10)\n",
        "        self.fc4 = nn.Linear(10,6)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = self.fc4(x)    \n",
        "        return x        \n",
        "    \n",
        "def train(model, train_loader, criterion, optimizer, num_epochs):\n",
        "    model.train()\n",
        "    \n",
        "    ram_usage=[]\n",
        "    cpu_usage=[]\n",
        "    backprop_time=[]\n",
        "    loss_list=[]\n",
        "\n",
        "    startMLP_train = time.time()\n",
        "    for epoch in range(num_epochs):  \n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device) \n",
        "            optimizer.zero_grad()            \n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            startMLP_bwd = time.time()\n",
        "            loss.backward()        \n",
        "            endMLP_bwd = time.time()\n",
        "            backprop_time.append((endMLP_bwd-startMLP_bwd)*1000)\n",
        "            optimizer.step()\n",
        "\n",
        "        loss_list.append(loss)\n",
        "        ram_usage.append(psutil.cpu_percent(4))\n",
        "        cpu_usage.append(psutil.virtual_memory()[3]/1000000000)\n",
        "        print('\\033[K',f'Epoch {epoch+1}/{num_epochs} | Loss: {round(loss.item(), 15)} | Backpropagation Time: {round(backprop_time[-1],2)} ms | CPU Usage: {round(cpu_usage[-1],2)} % | RAM Usage: {round(ram_usage[-1],2)} GB', end=\"\\r\")\n",
        "\n",
        "    endMLP_train = time.time()\n",
        "    train_time = endMLP_train - startMLP_train\n",
        "    backpropagation_time = np.max(backprop_time)\n",
        "    train_cpu_usage = np.max(cpu_usage)   \n",
        "    train_ram_usage = np.max(ram_usage)\n",
        "\n",
        "    info = {'Num_Epochs': num_epochs,\n",
        "            'Back_Propagation_Time': backpropagation_time,\n",
        "            'Max_CPU_usage': train_cpu_usage,\n",
        "            'Max_RAM_usage' : train_ram_usage,\n",
        "            'Train_Time' : train_time,\n",
        "            'Loss_List': loss_list }\n",
        "\n",
        "    return info\n",
        "\n",
        "def test_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device) \n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy: {accuracy}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = MLP_Model().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 94.50492483151892%537381414324 | Backpropagation Time: 0.6 ms | CPU Usage: 5.47 % | RAM Usage: 0.9 GBB\n"
          ]
        }
      ],
      "source": [
        "\n",
        "mlp_train_results = train(model, dataset[0][0], criterion, optimizer, num_epochs=10)\n",
        "\n",
        "test_model(model, dataset[0][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MLP_loss_list = np.array([x.item() for x in mlp_train_results['Loss_List']]) \n",
        "iteration =  range(1, mlp_train_results['Num_Epochs']+1)        \n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(iteration, MLP_loss_list, marker='o', linestyle='-',  color='b', label='Erro Treino 1')\n",
        "\n",
        "plt.title('Evolução do Ajuste do Erro')\n",
        "plt.xlabel('Iterações')\n",
        "plt.ylabel('Erro')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "INFERÊNCIA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "7RE1svm9cXkX",
        "D7ERosp1iM17",
        "CBD58aME1Rvd",
        "tbhg0iWQ1FX-"
      ],
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
