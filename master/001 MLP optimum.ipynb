{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Inicialização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import  torch\n",
        "import  torch.nn as nn\n",
        "import  torch.nn.functional as F\n",
        "import  torch.optim as optim\n",
        "import  psutil\n",
        "import  os\n",
        "import  time\n",
        "import  joblib\n",
        "import  warnings\n",
        "import  pandas as pd\n",
        "import  seaborn as sns\n",
        "import  snap7\n",
        "import  ctypes\n",
        "import  numpy as np\n",
        "import  matplotlib.pyplot as plt\n",
        "\n",
        "from    torch.utils.data import DataLoader, TensorDataset\n",
        "from    sklearn.model_selection import train_test_split\n",
        "from    sklearn.metrics import confusion_matrix, classification_report\n",
        "from    sklearn.ensemble import RandomForestClassifier\n",
        "from    sklearn.preprocessing import LabelEncoder\n",
        "from    sklearn.model_selection import GridSearchCV\n",
        "from    sklearn.preprocessing import StandardScaler\n",
        "from    sklearn.preprocessing import MinMaxScaler\n",
        "from    sklearn.model_selection import ParameterGrid\n",
        "#from   snap7.types import Areas, S7DataItem, S7WLWord, S7WLReal, S7WLTimer\n",
        "from    snap7.type import S7DataItem, Area, WordLen\n",
        "from    snap7.util import set_int, set_real, get_int, get_real, get_s5time\n",
        "from    imblearn.over_sampling import SMOTE\n",
        "from    imblearn.under_sampling import RandomUnderSampler\n",
        "from    imblearn.pipeline import Pipeline\n",
        "from    imblearn.combine import SMOTETomek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Carregar e Preparar Conjunto de Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UDI</th>\n",
              "      <th>Product ID</th>\n",
              "      <th>Type</th>\n",
              "      <th>Air temperature [K]</th>\n",
              "      <th>Process temperature [K]</th>\n",
              "      <th>Rotational speed [rpm]</th>\n",
              "      <th>Torque [Nm]</th>\n",
              "      <th>Tool wear [min]</th>\n",
              "      <th>Target</th>\n",
              "      <th>Failure Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>M14860</td>\n",
              "      <td>M</td>\n",
              "      <td>298.1</td>\n",
              "      <td>308.6</td>\n",
              "      <td>1551</td>\n",
              "      <td>42.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>No Failure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>L47181</td>\n",
              "      <td>L</td>\n",
              "      <td>298.2</td>\n",
              "      <td>308.7</td>\n",
              "      <td>1408</td>\n",
              "      <td>46.3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>No Failure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>L47182</td>\n",
              "      <td>L</td>\n",
              "      <td>298.1</td>\n",
              "      <td>308.5</td>\n",
              "      <td>1498</td>\n",
              "      <td>49.4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>No Failure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>L47183</td>\n",
              "      <td>L</td>\n",
              "      <td>298.2</td>\n",
              "      <td>308.6</td>\n",
              "      <td>1433</td>\n",
              "      <td>39.5</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>No Failure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>L47184</td>\n",
              "      <td>L</td>\n",
              "      <td>298.2</td>\n",
              "      <td>308.7</td>\n",
              "      <td>1408</td>\n",
              "      <td>40.0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>No Failure</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   UDI Product ID Type  Air temperature [K]  Process temperature [K]  \\\n",
              "0    1     M14860    M                298.1                    308.6   \n",
              "1    2     L47181    L                298.2                    308.7   \n",
              "2    3     L47182    L                298.1                    308.5   \n",
              "3    4     L47183    L                298.2                    308.6   \n",
              "4    5     L47184    L                298.2                    308.7   \n",
              "\n",
              "   Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Target Failure Type  \n",
              "0                    1551         42.8                0       0   No Failure  \n",
              "1                    1408         46.3                3       0   No Failure  \n",
              "2                    1498         49.4                5       0   No Failure  \n",
              "3                    1433         39.5                7       0   No Failure  \n",
              "4                    1408         40.0                9       0   No Failure  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# dados importados da plataforma KAGGLE - https://www.kaggle.com/datasets/shivamb/machine-predictive-maintenance-classification\n",
        "df = pd.read_csv(\"predictive_maintenance.csv\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* descartar as colunas desnecessárias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "df=df.drop(['Product ID','UDI','Target'],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* codificar a coluna de falhas para tipo int entre 0 e 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"'\\n0 - 112  - heat dissipation\\n1 - 9652 - no Failure\\n2 - 78   - overstrain\\n3 - 95   - power failure\\n4 - 18   - random failure\\n5 - 45   - tool wear\\n\""
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Perform label encoding\n",
        "df['Failure Type_encoded'] = label_encoder.fit_transform(df['Failure Type'])\n",
        "\n",
        "df['Failure Type_encoded'].value_counts()\n",
        "\n",
        "''''\n",
        "0 - 112  - heat dissipation\n",
        "1 - 9652 - no Failure\n",
        "2 - 78   - overstrain\n",
        "3 - 95   - power failure\n",
        "4 - 18   - random failure\n",
        "5 - 45   - tool wear\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* converter a coluna 'Type' (string) em outras duas separadas do tipo bool (uma para cada tipo de material) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Air temperature [K]</th>\n",
              "      <th>Process temperature [K]</th>\n",
              "      <th>Rotational speed [rpm]</th>\n",
              "      <th>Torque [Nm]</th>\n",
              "      <th>Tool wear [min]</th>\n",
              "      <th>Failure Type</th>\n",
              "      <th>Failure Type_encoded</th>\n",
              "      <th>Type_L</th>\n",
              "      <th>Type_M</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>298.1</td>\n",
              "      <td>308.6</td>\n",
              "      <td>1551</td>\n",
              "      <td>42.8</td>\n",
              "      <td>0</td>\n",
              "      <td>No Failure</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>298.2</td>\n",
              "      <td>308.7</td>\n",
              "      <td>1408</td>\n",
              "      <td>46.3</td>\n",
              "      <td>3</td>\n",
              "      <td>No Failure</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>298.1</td>\n",
              "      <td>308.5</td>\n",
              "      <td>1498</td>\n",
              "      <td>49.4</td>\n",
              "      <td>5</td>\n",
              "      <td>No Failure</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>298.2</td>\n",
              "      <td>308.6</td>\n",
              "      <td>1433</td>\n",
              "      <td>39.5</td>\n",
              "      <td>7</td>\n",
              "      <td>No Failure</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>298.2</td>\n",
              "      <td>308.7</td>\n",
              "      <td>1408</td>\n",
              "      <td>40.0</td>\n",
              "      <td>9</td>\n",
              "      <td>No Failure</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Air temperature [K]  Process temperature [K]  Rotational speed [rpm]  \\\n",
              "0                298.1                    308.6                    1551   \n",
              "1                298.2                    308.7                    1408   \n",
              "2                298.1                    308.5                    1498   \n",
              "3                298.2                    308.6                    1433   \n",
              "4                298.2                    308.7                    1408   \n",
              "\n",
              "   Torque [Nm]  Tool wear [min] Failure Type  Failure Type_encoded  Type_L  \\\n",
              "0         42.8                0   No Failure                     1   False   \n",
              "1         46.3                3   No Failure                     1    True   \n",
              "2         49.4                5   No Failure                     1    True   \n",
              "3         39.5                7   No Failure                     1    True   \n",
              "4         40.0                9   No Failure                     1    True   \n",
              "\n",
              "   Type_M  \n",
              "0    True  \n",
              "1   False  \n",
              "2   False  \n",
              "3   False  \n",
              "4   False  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.get_dummies(df, columns=['Type'], prefix='Type', drop_first=True)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* separar os dados em: dados de entrada (features), X  e dados de saída (label), y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definição do conjunto de dados de entrada e do conjunto de dados de saída\n",
        "\n",
        "X_raw = df.drop(['Failure Type','Failure Type_encoded'], axis=1).values\n",
        "y_raw= df['Failure Type_encoded'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Em aplicações do mundo real, a modelagem de classificação frequentemente enfrenta o problema de conjuntos de dados desequilibrados, onde o número de instâncias da classe majoritária é muito maior do que o da classe minoritária, o que dificulta o aprendizado adequado do modelo em relação à classe minoritária. Isso se torna um problema sério quando a informação contida na classe minoritária é mais importante como, por exemplo, no conjunto utilizado.\n",
        "\n",
        "* Uma das abordagens populares para resolver o problema de conjuntos de dados desequilibrados é a superamostragem da classe minoritária ou a subamostragem da classe majoritária. No entanto, essas abordagens possuem suas próprias limitações. No método tradicional de superamostragem, a ideia é duplicar aleatoriamente alguns exemplos da classe minoritária — essa técnica não adiciona novas informações ao conjunto de dados. Por outro lado, o método de subamostragem é realizado removendo aleatoriamente alguns exemplos da classe majoritária, o que resulta na perda de algumas informações originais dos dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de amostras antes balanceamento: 10000\n",
            "Total de amostras por falha:\n",
            "\n",
            " Failure Type_encoded\n",
            "1    9652\n",
            "0     112\n",
            "3      95\n",
            "2      78\n",
            "5      45\n",
            "4      18\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print('Total de amostras antes balanceamento:',df['Failure Type_encoded'].count())\n",
        "print('Total de amostras por falha:\\n\\n', df['Failure Type_encoded'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Uma solução para superar essas limitações é gerar novos exemplos sintetizados a partir da classe minoritária existente. Esse método é conhecido como Técnica de Superamostragem da Minoria Sintética (SMOTE). Existem muitas variações do SMOTE, mas neste artigo será explicado o método SMOTE-Tomek Links e sua implementação em Python. Esse método combina a superamostragem do SMOTE com a subamostragem dos Tomek Links.\n",
        "\n",
        "* O método SMOTE-Tomek Links, desenvolvido por Chawla et al. (2002) é uma combinação de técnicas que visa equilibrar os dados ao aumentar a representatividade da classe minoritária através da criação de novos exemplos sintéticos e ao mesmo tempo remover exemplos que são considerados ruidosos ou redundantes na classe majoritária. A implementação desta abordagem utilizando Python é apresentada, detalhando os passos e a lógica do algoritmo, assim como os resultados obtidos em diferentes conjuntos de dados desequilibrados.\n",
        "\n",
        "* A combinação das técnicas de superamostragem e subamostragem, especificamente utilizando o método SMOTE-Tomek Links, mostra-se eficaz na melhoria do desempenho dos modelos de classificação em conjuntos de dados desequilibrados. Esta abordagem permite ao modelo aprender de forma mais eficiente a partir da classe minoritária, mantendo a integridade e a diversidade da informação no conjunto de dados.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de amostras após balanceamento: 57868\n",
            "Total de amostras por falha:\n",
            "\n",
            " Type_encoded\n",
            "2    9652\n",
            "0    9649\n",
            "5    9647\n",
            "3    9645\n",
            "4    9645\n",
            "1    9630\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#implementação do método SMOTE no conunto de dados\n",
        "smt=SMOTETomek(sampling_strategy='auto',random_state=42)\n",
        "X_resampled, y_resampled = smt.fit_resample(X_raw, y_raw)\n",
        "\n",
        "# Convertendo para dataframe do pandas\n",
        "df_resampled = pd.DataFrame(X_resampled, columns=[f'feature_{i}' for i in range(X_resampled.shape[1])])\n",
        "df_resampled['Type_encoded'] = y_resampled \n",
        "\n",
        "df_resampled.head()\n",
        "\n",
        "#distribuição das classes após balanceamento\n",
        "print('Total de amostras após balanceamento:',df_resampled['Type_encoded'].count())\n",
        "print('Total de amostras por falha:\\n\\n', df_resampled['Type_encoded'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Temp_Ar</th>\n",
              "      <th>Temp_Pr</th>\n",
              "      <th>Vel_Spindle</th>\n",
              "      <th>Torque</th>\n",
              "      <th>Desg_Ferr</th>\n",
              "      <th>Mat_L</th>\n",
              "      <th>Mat_M</th>\n",
              "      <th>Tipo_Falha</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>298.1</td>\n",
              "      <td>308.6</td>\n",
              "      <td>1551.0</td>\n",
              "      <td>42.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>298.2</td>\n",
              "      <td>308.7</td>\n",
              "      <td>1408.0</td>\n",
              "      <td>46.3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>298.1</td>\n",
              "      <td>308.5</td>\n",
              "      <td>1498.0</td>\n",
              "      <td>49.4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>298.2</td>\n",
              "      <td>308.6</td>\n",
              "      <td>1433.0</td>\n",
              "      <td>39.5</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>298.2</td>\n",
              "      <td>308.7</td>\n",
              "      <td>1408.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Temp_Ar  Temp_Pr  Vel_Spindle  Torque  Desg_Ferr  Mat_L  Mat_M  Tipo_Falha\n",
              "0    298.1    308.6       1551.0    42.8        0.0    0.0    1.0           1\n",
              "1    298.2    308.7       1408.0    46.3        3.0    1.0    0.0           1\n",
              "2    298.1    308.5       1498.0    49.4        5.0    1.0    0.0           1\n",
              "3    298.2    308.6       1433.0    39.5        7.0    1.0    0.0           1\n",
              "4    298.2    308.7       1408.0    40.0        9.0    1.0    0.0           1"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_resampled = df_resampled.rename(columns={'feature_0':'Temp_Ar'})\n",
        "df_resampled = df_resampled.rename(columns={'feature_1':'Temp_Pr'})\n",
        "df_resampled = df_resampled.rename(columns={'feature_2':'Vel_Spindle'})\n",
        "df_resampled = df_resampled.rename(columns={'feature_3':'Torque'})\n",
        "df_resampled = df_resampled.rename(columns={'feature_4':'Desg_Ferr'})\n",
        "df_resampled = df_resampled.rename(columns={'feature_5':'Mat_L'})\n",
        "df_resampled = df_resampled.rename(columns={'feature_6':'Mat_M'})\n",
        "\n",
        "df_resampled = df_resampled.rename(columns={'Type_encoded':'Tipo_Falha'})\n",
        "\n",
        "df_resampled.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Metodo para normalização do conjunto de dados e formatação para as diferentes redes neurais (MLP e KAN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_Preditive_Maintenance_Dataset():\n",
        "\n",
        "    X_ = df_resampled.drop(['Tipo_Falha'], axis=\"columns\")\n",
        "\n",
        "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "    X_   = scaler.fit_transform(X_)    \n",
        "    joblib.dump(scaler, 'minmax_scaler.pkl')    \n",
        "\n",
        "    y_ = df_resampled['Tipo_Falha']\n",
        "\n",
        "    #convertendo os dados em tensores e atribuindo a sua excucção na CPU ou GPU (device) conforme disponibilidade avaliada no inicio do programa\n",
        "    X = torch.tensor(X_, dtype = torch.float32).to(device)\n",
        "    y = torch.tensor(y_.values, dtype = torch.long).to(device)  \n",
        "\n",
        "    #separa os dados entre conjunto de dados para treinamento (80%) e conjunto de dados para teste/validação (20% <-> teste_size=0.2)\n",
        "    train_data_, test_data_, train_target_, test_target_ = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # geração de  mini batches para melhorar desempenho do treinamento\n",
        "    train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_data_, train_target_), batch_size=10, shuffle=True)   \n",
        "    validation_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_data_, test_target_), batch_size=10, shuffle=False)  \n",
        "\n",
        "    #conjunto de dados no formato a ser utilizado no redes MLP\n",
        "    train_data_loader   = train_loader\n",
        "    test_data_loader    = validation_loader\n",
        "\n",
        "    train_data      = train_data_    \n",
        "    test_data       = test_data_\n",
        "    train_labels    = train_target_\n",
        "    test_label      = test_target_\n",
        "\n",
        "    MLP_dataset     = [train_data, train_labels, test_data, test_label, train_data_loader, test_data_loader ]  \n",
        "\n",
        "    return MLP_dataset\n",
        "\n",
        "dataset =load_Preditive_Maintenance_Dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Implementação Rede Neural Multilayer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class MLP_Model(nn.Module):  \n",
        "    def __init__(self, layer_sizes, dropout_prob=0.5):\n",
        "        super(MLP_Model, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.dropouts = nn.ModuleList()\n",
        "        \n",
        "        for i in range(len(layer_sizes) - 1):\n",
        "            self.layers.append(nn.Linear(layer_sizes[i], layer_sizes[i + 1]))\n",
        "            if i < len(layer_sizes) - 2: \n",
        "                self.dropouts.append(nn.Dropout(p=dropout_prob))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        for i in range(len(self.layers) - 1):\n",
        "            x = F.relu(self.layers[i](x))\n",
        "            x = self.dropouts[i](x)\n",
        "        x = self.layers[-1](x)\n",
        "        return x\n",
        "\n",
        "def initialize_weights(model):\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, nn.Linear):\n",
        "            nn.init.kaiming_normal_(layer.weight)\n",
        "            if layer.bias is not None:\n",
        "                nn.init.zeros_(layer.bias)\n",
        "\n",
        "def train(model, train_loader, criterion, optimizer, num_epochs, device):\n",
        "    model.train()\n",
        "\n",
        "    ram_usage       = []\n",
        "    cpu_usage       = []\n",
        "    backprop_time   = []\n",
        "    loss_list       = []\n",
        "\n",
        "    startMLP_train = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            startMLP_bwd = time.time()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            endMLP_bwd = time.time()\n",
        "            backprop_time.append((endMLP_bwd - startMLP_bwd) * 1000)\n",
        "\n",
        "        loss_list.append(loss.item())\n",
        "        ram_usage.append(psutil.virtual_memory().percent)\n",
        "        cpu_usage.append(psutil.cpu_percent(interval=1))\n",
        "        print(f'Epoch {epoch+1}/{num_epochs} | Loss: {round(loss.item(), 4)} | Backpropagation Time: {round(backprop_time[-1], 2)} ms | CPU Usage: {round(cpu_usage[-1], 2)} % | RAM Usage: {round(ram_usage[-1], 2)} %', end=\"\\r\")\n",
        "\n",
        "    endMLP_train = time.time()\n",
        "   \n",
        "    train_time = endMLP_train - startMLP_train\n",
        "    backpropagation_time = np.mean(backprop_time)\n",
        "    max_cpu_usage = np.max(cpu_usage)   \n",
        "    max_ram_usage = np.max(ram_usage)\n",
        "\n",
        "    info = {\n",
        "        'Num_Epochs': num_epochs,\n",
        "        'Back_Propagation_Time': backpropagation_time,\n",
        "        'Max_CPU_usage': max_cpu_usage,\n",
        "        'Max_RAM_usage': max_ram_usage,\n",
        "        'Train_Time': train_time,\n",
        "        'Loss_List': loss_list     }\n",
        "\n",
        "    return info\n",
        "\n",
        "def test_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "def run_grid_search(train_data, train_labels, test_data, test_labels, param_grid, num_epochs, device):\n",
        "    results = []\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_data, train_labels), batch_size=64, shuffle=True)   \n",
        "    test_loader  = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_data, test_labels), batch_size=64, shuffle=False)  \n",
        "    \n",
        "    for params in ParameterGrid(param_grid):\n",
        "\n",
        "        print('Configuração em execução: ',params)\n",
        "\n",
        "        layer_sizes = [7] + params['hidden_layers'] + [6]\n",
        "        model = MLP_Model(layer_sizes, dropout_prob=params['dropout_prob']).to(device)\n",
        "        initialize_weights(model)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'], weight_decay=params['weight_decay'])\n",
        "        train_results = train(model, train_loader, criterion, optimizer, params['epochs'], device)\n",
        "        accuracy = test_model(model, test_loader, device)\n",
        "        result = {\n",
        "            'params': params,\n",
        "            'num_parameters': sum(p.numel() for p in model.parameters() if p.requires_grad),\n",
        "            'accuracy': accuracy,\n",
        "            'loss_list': train_results['Loss_List'],\n",
        "            'training_time' :  train_results['Train_Time'],\n",
        "            'backpropagation_time' : train_results['Back_Propagation_Time'],\n",
        "            'max_cpu_usage': train_results['Max_CPU_usage'],\n",
        "            'max_ram_usage': train_results['Max_RAM_usage']\n",
        "        }\n",
        "\n",
        "        results.append(result)\n",
        "    \n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuração em execução:  {'dropout_prob': 0.0, 'epochs': 10, 'hidden_layers': [10], 'learning_rate': 0.01, 'weight_decay': 0.0}\n",
            "Configuração em execução:  {'dropout_prob': 0.0, 'epochs': 10, 'hidden_layers': [10], 'learning_rate': 0.01, 'weight_decay': 0.0001}\n",
            "Configuração em execução:  {'dropout_prob': 0.0, 'epochs': 10, 'hidden_layers': [10], 'learning_rate': 0.01, 'weight_decay': 0.001}\n",
            "Configuração em execução:  {'dropout_prob': 0.0, 'epochs': 10, 'hidden_layers': [10], 'learning_rate': 0.005, 'weight_decay': 0.0}\n",
            "Configuração em execução:  {'dropout_prob': 0.0, 'epochs': 10, 'hidden_layers': [10], 'learning_rate': 0.005, 'weight_decay': 0.0001}\n",
            "Configuração em execução:  {'dropout_prob': 0.0, 'epochs': 10, 'hidden_layers': [10], 'learning_rate': 0.005, 'weight_decay': 0.001}\n",
            "Configuração em execução:  {'dropout_prob': 0.0, 'epochs': 10, 'hidden_layers': [10], 'learning_rate': 0.001, 'weight_decay': 0.0}\n",
            "Configuração em execução:  {'dropout_prob': 0.0, 'epochs': 10, 'hidden_layers': [10], 'learning_rate': 0.001, 'weight_decay': 0.0001}\n",
            "Configuração em execução:  {'dropout_prob': 0.0, 'epochs': 10, 'hidden_layers': [10], 'learning_rate': 0.001, 'weight_decay': 0.001}\n",
            "Configuração em execução:  {'dropout_prob': 0.0, 'epochs': 10, 'hidden_layers': [10], 'learning_rate': 0.0001, 'weight_decay': 0.0}\n",
            "Epoch 2/10 | Loss: 1.6232 | Backpropagation Time: 0.6 ms | CPU Usage: 0.7 % | RAM Usage: 32.6 %\r"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[41], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m num_epochs       \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Executar a busca em grade\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_grid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Armazenar os resultados em um DataFrame\u001b[39;00m\n\u001b[1;32m     21\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n",
            "Cell \u001b[0;32mIn[40], line 109\u001b[0m, in \u001b[0;36mrun_grid_search\u001b[0;34m(train_data, train_labels, test_data, test_labels, param_grid, num_epochs, device)\u001b[0m\n\u001b[1;32m    107\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m    108\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m], weight_decay\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 109\u001b[0m train_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m test_model(model, test_loader, device)\n\u001b[1;32m    111\u001b[0m result \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: params,\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters() \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mrequires_grad),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_ram_usage\u001b[39m\u001b[38;5;124m'\u001b[39m: train_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMax_RAM_usage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    120\u001b[0m }\n",
            "Cell \u001b[0;32mIn[40], line 43\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, criterion, optimizer, num_epochs, device)\u001b[0m\n\u001b[1;32m     41\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     42\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 43\u001b[0m startMLP_bwd \u001b[38;5;241m=\u001b[39m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     45\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "# Definição dos hiperparâmetros para a busca em grade\n",
        "param_grid = {\n",
        "    'hidden_layers': [[10], [20, 10], [10, 10, 10], [50, 50, 50], [128, 64, 32], [128,64,32,16]],\n",
        "    'learning_rate': [0.01, 0.005, 0.001, 0.0001],\n",
        "    'weight_decay' : [0.0, 0.0001, 0.001],  # Regularização L2\n",
        "    'dropout_prob' : [0.0, 0.3, 0.5],  # Probabilidade de dropout\n",
        "    'epochs'       : [10, 50, 100, 200, 350]\n",
        "    }\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_data      = dataset[0]\n",
        "train_labels    = dataset[1]\n",
        "test_data       = dataset[2]\n",
        "test_labels     = dataset[3]\n",
        "num_epochs       = 1\n",
        "\n",
        "# Executar a busca em grade\n",
        "results = run_grid_search(train_data, train_labels, test_data, test_labels, param_grid, num_epochs, device)\n",
        "\n",
        "# Armazenar os resultados em um DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv('grid_search_results.csv', index=False)\n",
        "\n",
        "# Exibir os melhores resultados\n",
        "best_result = max(results, key=lambda x: x['accuracy'])\n",
        "\n",
        "print(f\"Number of Parameters: {best_result['num_parameters']}\")\n",
        "print(f\"Backpropagation Time: {best_result['backpropagation_time']}%\")\n",
        "print(f\"Max CPU Usage: {best_result['max_cpu_usage']}%\")\n",
        "print(f\"Max RAM Usage Time: {best_result['max_ram_usage']}%\")\n",
        "print(f\"Training Time: {best_result['training_time']}%\")\n",
        "print(f\"Accuracy: {best_result['accuracy']}%\")\n",
        "print(f\"\\nMelhor configuração: {best_result['params']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MLP_loss_list = np.array([x.item() for x in mlp_train_results['Loss_List']]) \n",
        "iteration =  range(1, mlp_train_results['Num_Epochs']+1)        \n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(iteration, MLP_loss_list, marker='o', linestyle='-',  color='b', label='Erro Treino 1')\n",
        "\n",
        "plt.title('Evolução do Ajuste do Erro')\n",
        "plt.xlabel('Iterações')\n",
        "plt.ylabel('Erro')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "INFERÊNCIA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_2d= X_raw[2581].reshape(1, -1)\n",
        "\n",
        "print(X_2d)\n",
        "print(y_raw[2581])\n",
        "\n",
        "scaler = joblib.load('minmax_scaler.pkl')\n",
        "\n",
        "# Aplicar a normalização aos novos dados\n",
        "X_new_scaled = scaler.transform(X_2d)\n",
        "\n",
        "# Converter para tensor PyTorch\n",
        "X_new_scaled_tensor = torch.tensor(X_new_scaled, dtype=torch.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_real_values(client, db_number, start_address, number_values):\n",
        "\n",
        "    values = []\n",
        "\n",
        "    try:\n",
        "        # Conectando ao PLC\n",
        "        #client.connect(plc_ip, 0, 1)\n",
        "\n",
        "            # Lendo  valores reais (floats) do DB\n",
        "        data = client.db_read(db_number, start_address, number_values*4)  # 4 bytes para cada valor real\n",
        "\n",
        "            # Convertendo os bytes em floats\n",
        "        values = [snap7.util.get_real(data, i) for i in range(0, number_values*4, 4)]\n",
        "\n",
        "    except Snap7Exception as e:\n",
        "        print(f\"Erro ao ler dados do PLC: {e}\")    \n",
        "        \n",
        "    return values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def write_data_to_plc(client, dbnumber,offset, value):\n",
        "\n",
        "    realValue = bytearray(4)\n",
        "    \n",
        "    set_real(realValue, 0,value)\n",
        "\n",
        "    client.db_write(dbnumber,offset,realValue)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "plc_ip = '192.168.0.1'\n",
        "db_number = 2\n",
        "start_address = 0\n",
        "read_number_of_values = 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "linear(): argument 'input' (position 1) must be Tensor, not DataFrame",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[52], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m dframe \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(features)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 15\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m write_data_to_plc(s71511T,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m0\u001b[39m,predicted[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     18\u001b[0m write_data_to_plc(s71511T,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,predicted[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m])\n",
            "File \u001b[0;32m~/anaconda3/envs/diss3_12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/diss3_12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[44], line 12\u001b[0m, in \u001b[0;36mMLP_Model.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[0;32m---> 12\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     13\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[1;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x))\n",
            "File \u001b[0;32m~/anaconda3/envs/diss3_12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/diss3_12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/diss3_12/lib/python3.12/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not DataFrame"
          ]
        }
      ],
      "source": [
        "s71511T = snap7.client.Client()\n",
        "s71511T.connect(plc_ip, 0, 1)\n",
        "\n",
        "if  s71511T.get_connected() == True:\n",
        "    \n",
        "    while True:\n",
        "        values=read_real_values(s71511T,2,0,7)\n",
        "\n",
        "        features = np.array(values)\n",
        "        features = features.reshape(1,7)\n",
        "\n",
        "        dframe = pd.DataFrame(features)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(dframe)\n",
        "\n",
        "        write_data_to_plc(s71511T,3,0,predicted[0][0])\n",
        "        write_data_to_plc(s71511T,3,4,predicted[0][1])\n",
        "        write_data_to_plc(s71511T,3,8,predicted[0][2])\n",
        "        write_data_to_plc(s71511T,3,12,predicted[0][3])\n",
        "        write_data_to_plc(s71511T,3,16,predicted[0][4])\n",
        "        write_data_to_plc(s71511T,3,20,predicted[0][5])\n",
        "else:\n",
        "    print(\"Sem conexão com o CLP\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "7RE1svm9cXkX",
        "D7ERosp1iM17",
        "CBD58aME1Rvd",
        "tbhg0iWQ1FX-"
      ],
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
