{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin\n",
    "from sklearn.utils.multiclass import check_classification_targets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from imodelsx.kan.kan_modules import KANModule, KANGAMModule\n",
    "\n",
    "\n",
    "from typing import List\n",
    "\n",
    "#import  psutil\n",
    "#import  os\n",
    "#import  time\n",
    "import  joblib\n",
    "import  warnings\n",
    "import  pandas as pd\n",
    "import  seaborn as sns\n",
    "import  snap7\n",
    "import  ctypes\n",
    "import  struct\n",
    "\n",
    "import  matplotlib.pyplot as plt\n",
    "\n",
    "from    torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from    sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from    sklearn.preprocessing import LabelEncoder\n",
    "from    sklearn.model_selection import GridSearchCV\n",
    "from    sklearn.preprocessing import StandardScaler\n",
    "from    sklearn.preprocessing import MinMaxScaler\n",
    "from    sklearn.model_selection import ParameterGrid\n",
    "from    snap7.type import S7DataItem, Area, WordLen\n",
    "from    snap7.util import *\n",
    "from    imblearn.over_sampling import SMOTE\n",
    "from    imblearn.under_sampling import RandomUnderSampler\n",
    "from    imblearn.pipeline import Pipeline\n",
    "from    imblearn.combine import SMOTETomek \n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "else:\n",
    "  device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação Efficient KAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class KANLinearModule(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features,\n",
    "        out_features,\n",
    "        grid_size=5,\n",
    "        spline_order=3,\n",
    "        scale_noise=0.1,\n",
    "        scale_base=1.0,\n",
    "        scale_spline=1.0,\n",
    "        enable_standalone_scale_spline=True,\n",
    "        base_activation=torch.nn.SiLU,\n",
    "        grid_eps=0.02,\n",
    "        grid_range=[-1, 1],\n",
    "    ):\n",
    "        super(KANLinearModule, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.grid_size = grid_size\n",
    "        self.spline_order = spline_order\n",
    "\n",
    "        h = (grid_range[1] - grid_range[0]) / grid_size\n",
    "        grid = (\n",
    "            (\n",
    "                torch.arange(-spline_order, grid_size + spline_order + 1) * h\n",
    "                + grid_range[0]\n",
    "            )\n",
    "            .expand(in_features, -1)\n",
    "            .contiguous()\n",
    "        )\n",
    "        self.register_buffer(\"grid\", grid)\n",
    "\n",
    "        self.base_weight = torch.nn.Parameter(\n",
    "            torch.Tensor(out_features, in_features))\n",
    "        self.spline_weight = torch.nn.Parameter(\n",
    "            torch.Tensor(out_features, in_features, grid_size + spline_order)\n",
    "        )\n",
    "        if enable_standalone_scale_spline:\n",
    "            self.spline_scaler = torch.nn.Parameter(\n",
    "                torch.Tensor(out_features, in_features)\n",
    "            )\n",
    "\n",
    "        self.scale_noise = scale_noise\n",
    "        self.scale_base = scale_base\n",
    "        self.scale_spline = scale_spline\n",
    "        self.enable_standalone_scale_spline = enable_standalone_scale_spline\n",
    "        self.base_activation = base_activation()\n",
    "        self.grid_eps = grid_eps\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.kaiming_uniform_(\n",
    "            self.base_weight, a=math.sqrt(5) * self.scale_base)\n",
    "        with torch.no_grad():\n",
    "            noise = (\n",
    "                (\n",
    "                    torch.rand(self.grid_size + 1,\n",
    "                               self.in_features, self.out_features)\n",
    "                    - 1 / 2\n",
    "                )\n",
    "                * self.scale_noise\n",
    "                / self.grid_size\n",
    "            )\n",
    "            self.spline_weight.data.copy_(\n",
    "                (self.scale_spline if not self.enable_standalone_scale_spline else 1.0)\n",
    "                * self.curve2coeff(\n",
    "                    self.grid.T[self.spline_order: -self.spline_order],\n",
    "                    noise,\n",
    "                )\n",
    "            )\n",
    "            if self.enable_standalone_scale_spline:\n",
    "                # torch.nn.init.constant_(self.spline_scaler, self.scale_spline)\n",
    "                torch.nn.init.kaiming_uniform_(\n",
    "                    self.spline_scaler, a=math.sqrt(5) * self.scale_spline)\n",
    "\n",
    "    def b_splines(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Compute the B-spline bases for the given input tensor.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: B-spline bases tensor of shape (batch_size, in_features, grid_size + spline_order).\n",
    "        \"\"\"\n",
    "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
    "\n",
    "        grid: torch.Tensor = (\n",
    "            self.grid\n",
    "        )  # (in_features, grid_size + 2 * spline_order + 1)\n",
    "        x = x.unsqueeze(-1)\n",
    "        bases = ((x >= grid[:, :-1]) & (x < grid[:, 1:])).to(x.dtype)\n",
    "        for k in range(1, self.spline_order + 1):\n",
    "            bases = (\n",
    "                (x - grid[:, : -(k + 1)])\n",
    "                / (grid[:, k:-1] - grid[:, : -(k + 1)])\n",
    "                * bases[:, :, :-1]\n",
    "            ) + (\n",
    "                (grid[:, k + 1:] - x)\n",
    "                / (grid[:, k + 1:] - grid[:, 1:(-k)])\n",
    "                * bases[:, :, 1:]\n",
    "            )\n",
    "\n",
    "        assert bases.size() == (\n",
    "            x.size(0),\n",
    "            self.in_features,\n",
    "            self.grid_size + self.spline_order,\n",
    "        )\n",
    "        return bases.contiguous()\n",
    "\n",
    "    def curve2coeff(self, x: torch.Tensor, y: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Compute the coefficients of the curve that interpolates the given points.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n",
    "            y (torch.Tensor): Output tensor of shape (batch_size, in_features, out_features).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Coefficients tensor of shape (out_features, in_features, grid_size + spline_order).\n",
    "        \"\"\"\n",
    "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
    "        assert y.size() == (x.size(0), self.in_features, self.out_features)\n",
    "\n",
    "        A = self.b_splines(x).transpose(\n",
    "            0, 1\n",
    "        )  # (in_features, batch_size, grid_size + spline_order)\n",
    "        B = y.transpose(0, 1)  # (in_features, batch_size, out_features)\n",
    "        solution = torch.linalg.lstsq(\n",
    "            A, B\n",
    "        ).solution  # (in_features, grid_size + spline_order, out_features)\n",
    "        result = solution.permute(\n",
    "            2, 0, 1\n",
    "        )  # (out_features, in_features, grid_size + spline_order)\n",
    "\n",
    "        assert result.size() == (\n",
    "            self.out_features,\n",
    "            self.in_features,\n",
    "            self.grid_size + self.spline_order,\n",
    "        )\n",
    "        return result.contiguous()\n",
    "\n",
    "    @property\n",
    "    def scaled_spline_weight(self):\n",
    "        return self.spline_weight * (\n",
    "            self.spline_scaler.unsqueeze(-1)\n",
    "            if self.enable_standalone_scale_spline\n",
    "            else 1.0\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
    "\n",
    "        base_output = F.linear(self.base_activation(x), self.base_weight)\n",
    "        spline_output = F.linear(\n",
    "            self.b_splines(x).view(x.size(0), -1),\n",
    "            self.scaled_spline_weight.view(self.out_features, -1),\n",
    "        )\n",
    "        return base_output + spline_output\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update_grid(self, x: torch.Tensor, margin=0.01):\n",
    "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
    "        batch = x.size(0)\n",
    "\n",
    "        splines = self.b_splines(x)  # (batch, in, coeff)\n",
    "        splines = splines.permute(1, 0, 2)  # (in, batch, coeff)\n",
    "        orig_coeff = self.scaled_spline_weight  # (out, in, coeff)\n",
    "        orig_coeff = orig_coeff.permute(1, 2, 0)  # (in, coeff, out)\n",
    "        unreduced_spline_output = torch.bmm(\n",
    "            splines, orig_coeff)  # (in, batch, out)\n",
    "        unreduced_spline_output = unreduced_spline_output.permute(\n",
    "            1, 0, 2\n",
    "        )  # (batch, in, out)\n",
    "\n",
    "        # sort each channel individually to collect data distribution\n",
    "        x_sorted = torch.sort(x, dim=0)[0]\n",
    "        grid_adaptive = x_sorted[\n",
    "            torch.linspace(\n",
    "                0, batch - 1, self.grid_size + 1, dtype=torch.int64, device=x.device\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        uniform_step = (x_sorted[-1] - x_sorted[0] +\n",
    "                        2 * margin) / self.grid_size\n",
    "        grid_uniform = (\n",
    "            torch.arange(\n",
    "                self.grid_size + 1, dtype=torch.float32, device=x.device\n",
    "            ).unsqueeze(1)\n",
    "            * uniform_step\n",
    "            + x_sorted[0]\n",
    "            - margin\n",
    "        )\n",
    "\n",
    "        grid = self.grid_eps * grid_uniform + \\\n",
    "            (1 - self.grid_eps) * grid_adaptive\n",
    "        grid = torch.concatenate(\n",
    "            [\n",
    "                grid[:1]\n",
    "                - uniform_step\n",
    "                * torch.arange(self.spline_order, 0, -1,\n",
    "                               device=x.device).unsqueeze(1),\n",
    "                grid,\n",
    "                grid[-1:]\n",
    "                + uniform_step\n",
    "                * torch.arange(1, self.spline_order + 1,\n",
    "                               device=x.device).unsqueeze(1),\n",
    "            ],\n",
    "            dim=0,\n",
    "        )\n",
    "\n",
    "        self.grid.copy_(grid.T)\n",
    "        self.spline_weight.data.copy_(\n",
    "            self.curve2coeff(x, unreduced_spline_output))\n",
    "\n",
    "    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n",
    "        \"\"\"\n",
    "        Compute the regularization loss.\n",
    "\n",
    "        This is a dumb simulation of the original L1 regularization as stated in the\n",
    "        paper, since the original one requires computing absolutes and entropy from the\n",
    "        expanded (batch, in_features, out_features) intermediate tensor, which is hidden\n",
    "        behind the F.linear function if we want an memory efficient implementation.\n",
    "\n",
    "        The L1 regularization is now computed as mean absolute value of the spline\n",
    "        weights. The authors implementation also includes this term in addition to the\n",
    "        sample-based regularization.\n",
    "        \"\"\"\n",
    "        l1_fake = self.spline_weight.abs().mean(-1)\n",
    "        regularization_loss_activation = l1_fake.sum()\n",
    "        p = l1_fake / regularization_loss_activation\n",
    "        regularization_loss_entropy = -torch.sum(p * p.log())\n",
    "        return (\n",
    "            regularize_activation * regularization_loss_activation\n",
    "            + regularize_entropy * regularization_loss_entropy\n",
    "        )\n",
    "\n",
    "\n",
    "class KANModule(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        layers_hidden,\n",
    "        grid_size=5,\n",
    "        spline_order=3,\n",
    "        scale_noise=0.1,\n",
    "        scale_base=1.0,\n",
    "        scale_spline=1.0,\n",
    "        base_activation=torch.nn.SiLU,\n",
    "        grid_eps=0.02,\n",
    "        grid_range=[-1, 1],\n",
    "    ):\n",
    "        super(KANModule, self).__init__()\n",
    "        self.grid_size = grid_size\n",
    "        self.spline_order = spline_order\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for in_features, out_features in zip(layers_hidden, layers_hidden[1:]):\n",
    "            self.layers.append(\n",
    "                KANLinearModule(\n",
    "                    in_features,\n",
    "                    out_features,\n",
    "                    grid_size=grid_size,\n",
    "                    spline_order=spline_order,\n",
    "                    scale_noise=scale_noise,\n",
    "                    scale_base=scale_base,\n",
    "                    scale_spline=scale_spline,\n",
    "                    base_activation=base_activation,\n",
    "                    grid_eps=grid_eps,\n",
    "                    grid_range=grid_range,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, update_grid=False):\n",
    "        for layer in self.layers:\n",
    "            if update_grid:\n",
    "                layer.update_grid(x)\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n",
    "        return sum(\n",
    "            layer.regularization_loss(\n",
    "                regularize_activation, regularize_entropy)\n",
    "            for layer in self.layers\n",
    "        )\n",
    "\n",
    "\n",
    "class KANGAMModule(torch.nn.Module):\n",
    "    '''Learn a KAN model on each individual input feature\n",
    "    '''\n",
    "\n",
    "    def __init__(self, num_features, layers_hidden: List[int], n_classes, **kwargs):\n",
    "        super(KANGAMModule, self).__init__()\n",
    "        self.models = torch.nn.ModuleList([\n",
    "            KANModule(\n",
    "                layers_hidden=[1] + layers_hidden + [1],\n",
    "                **kwargs)\n",
    "            for _ in range(num_features)\n",
    "        ])\n",
    "        self.linear = torch.nn.Linear(num_features, n_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, update_grid=False):\n",
    "\n",
    "        features = torch.stack(\n",
    "            [model(x[:, i:i + 1], update_grid)\n",
    "             for i, model in enumerate(self.models)],\n",
    "            dim=1)\n",
    "\n",
    "        features = features.view(x.size(0), -1)\n",
    "        return self.linear(features)\n",
    "\n",
    "    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0, regularize_ridge=1.0):\n",
    "        return sum(\n",
    "            layer.regularization_loss(\n",
    "                regularize_activation, regularize_entropy)\n",
    "            for model in self.models\n",
    "            for layer in model.layers\n",
    "        ) + regularize_ridge * self.linear.weight.norm(p=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KAN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KAN(BaseEstimator):\n",
    "    def __init__(self,\n",
    "                 hidden_layer_size: int = 64,\n",
    "                 hidden_layer_sizes: List[int] = None,\n",
    "                 regularize_activation: float = 1.0, regularize_entropy: float = 1.0, regularize_ridge: float = 0.0,\n",
    "                 test_size=0.2, random_state=42, shuffle=True,\n",
    "                 device: str = 'cpu',\n",
    "                 **kwargs):\n",
    "        '''\n",
    "        Params\n",
    "        ------\n",
    "        hidden_layer_size : int\n",
    "            If int, number of neurons in the hidden layer (assumes single hidden layer)\n",
    "        hidden_layer_sizes: List with length (n_layers - 2)\n",
    "            The ith element represents the number of neurons in the ith hidden layer.\n",
    "            If this is passed, will override hidden_layer_size\n",
    "            e.g. [32, 64] would have a layer with 32 hidden units followed by a layer with 64 hidden units\n",
    "            (input and output shape are inferred by the data passed)\n",
    "        regularize_activation: float\n",
    "            Activation regularization parameter\n",
    "        regularize_entropy: float\n",
    "            Entropy regularization parameter\n",
    "        regularize_ridge: float\n",
    "            Ridge regularization parameter (only applies to KANGAM)\n",
    "        kwargs can be any of these more detailed KAN parameters\n",
    "            grid_size=5,\n",
    "            spline_order=3,\n",
    "            scale_noise=0.1,\n",
    "            scale_base=1.0,\n",
    "            scale_spline=1.0,\n",
    "            base_activation=torch.nn.SiLU,\n",
    "            grid_eps=0.02,\n",
    "            grid_range=[-1, 1],\n",
    "        '''\n",
    "        if hidden_layer_sizes is not None:\n",
    "            self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        else:\n",
    "            self.hidden_layer_sizes = [hidden_layer_size]\n",
    "        self.device = device\n",
    "        self.regularize_activation = regularize_activation\n",
    "        self.regularize_entropy = regularize_entropy\n",
    "        self.regularize_ridge = regularize_ridge\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def fit(self, X, y, batch_size=512, lr=1e-3, weight_decay=1e-4, gamma=0.8):\n",
    "        if isinstance(self, ClassifierMixin):\n",
    "            check_classification_targets(y)\n",
    "            self.classes_, y = np.unique(y, return_inverse=True)\n",
    "            num_outputs = len(self.classes_)\n",
    "            y = torch.tensor(y, dtype=torch.long)\n",
    "        else:\n",
    "            num_outputs = 1\n",
    "            y = torch.tensor(y, dtype=torch.float32)\n",
    "        X = torch.tensor(X, dtype=torch.float32)\n",
    "        num_features = X.shape[1]\n",
    "\n",
    "        if isinstance(self, (KANGAMClassifier, KANGAMRegressor)):\n",
    "            self.model = KANGAMModule(\n",
    "                num_features=num_features,\n",
    "                layers_hidden=self.hidden_layer_sizes,\n",
    "                n_classes=num_outputs,\n",
    "                **self.kwargs\n",
    "            ).to(self.device)\n",
    "        else:\n",
    "            self.model = KANModule(\n",
    "                layers_hidden=[num_features] +\n",
    "                self.hidden_layer_sizes + [num_outputs],\n",
    "            ).to(self.device)\n",
    "\n",
    "        X_train, X_tune, y_train, y_tune = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "        dset_train = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "        dset_tune = torch.utils.data.TensorDataset(X_tune, y_tune)\n",
    "        loader_train = DataLoader(dset_train, batch_size=batch_size, shuffle=True)\n",
    "        loader_tune = DataLoader(dset_tune, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        optimizer = optim.AdamW(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma)\n",
    "\n",
    "        # Define loss\n",
    "        if isinstance(self, ClassifierMixin):\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        else:\n",
    "            criterion = nn.MSELoss()\n",
    "        tune_losses = []\n",
    "        for epoch in tqdm(range(100)):\n",
    "            self.model.train()\n",
    "            for x, labs in loader_train:\n",
    "                x = x.view(-1, num_features).to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                output = self.model(x).squeeze()\n",
    "                loss = criterion(output, labs.to(self.device).squeeze())\n",
    "                if isinstance(self, (KANGAMClassifier, KANGAMRegressor)):\n",
    "                    loss += self.model.regularization_loss(\n",
    "                        self.regularize_activation, self.regularize_entropy, self.regularize_ridge)\n",
    "                else:\n",
    "                    loss += self.model.regularization_loss(\n",
    "                        self.regularize_activation, self.regularize_entropy)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Validation\n",
    "            self.model.eval()\n",
    "            tune_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for x, labs in loader_tune:\n",
    "                    x = x.view(-1, num_features).to(self.device)\n",
    "                    output = self.model(x).squeeze()\n",
    "                    tune_loss += criterion(output,\n",
    "                                           labs.to(self.device).squeeze()).item()\n",
    "            tune_loss /= len(loader_tune)\n",
    "            tune_losses.append(tune_loss)\n",
    "            scheduler.step()\n",
    "\n",
    "            # apply early stopping\n",
    "            if len(tune_losses) > 3 and tune_losses[-1] > tune_losses[-2]:\n",
    "                print(\"\\tEarly stopping\")\n",
    "                return self\n",
    "\n",
    "        return self\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict(self, X):\n",
    "        X = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
    "        output = self.model(X)\n",
    "        if isinstance(self, ClassifierMixin):\n",
    "            return self.classes_[output.argmax(dim=1).cpu().numpy()]\n",
    "        else:\n",
    "            return output.cpu().numpy()\n",
    "\n",
    "\n",
    "class KANClassifier(KAN, ClassifierMixin):\n",
    "    @torch.no_grad()\n",
    "    def predict_proba(self, X):\n",
    "        X = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
    "        output = self.model(X)\n",
    "        return torch.nn.functional.softmax(output, dim=1).cpu().numpy()\n",
    "\n",
    "\n",
    "class KANRegressor(KAN, RegressorMixin):\n",
    "    pass\n",
    "\n",
    "\n",
    "class KANGAMClassifier(KANClassifier):\n",
    "    pass\n",
    "\n",
    "\n",
    "class KANGAMRegressor(KANRegressor):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UDI</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>Target</th>\n",
       "      <th>Failure Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M14860</td>\n",
       "      <td>M</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1551</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>L47181</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>46.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>No Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>L47182</td>\n",
       "      <td>L</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.5</td>\n",
       "      <td>1498</td>\n",
       "      <td>49.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>No Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>L47183</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1433</td>\n",
       "      <td>39.5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>No Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>L47184</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>No Failure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UDI Product ID Type  Air temperature [K]  Process temperature [K]  \\\n",
       "0    1     M14860    M                298.1                    308.6   \n",
       "1    2     L47181    L                298.2                    308.7   \n",
       "2    3     L47182    L                298.1                    308.5   \n",
       "3    4     L47183    L                298.2                    308.6   \n",
       "4    5     L47184    L                298.2                    308.7   \n",
       "\n",
       "   Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Target Failure Type  \n",
       "0                    1551         42.8                0       0   No Failure  \n",
       "1                    1408         46.3                3       0   No Failure  \n",
       "2                    1498         49.4                5       0   No Failure  \n",
       "3                    1433         39.5                7       0   No Failure  \n",
       "4                    1408         40.0                9       0   No Failure  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dados importados da plataforma KAGGLE - https://www.kaggle.com/datasets/shivamb/machine-predictive-maintenance-classification\n",
    "df = pd.read_csv(\"predictive_maintenance.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['Product ID','UDI','Target'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'\\n0 - 112  - heat dissipation\\n1 - 9652 - no Failure\\n2 - 78   - overstrain\\n3 - 95   - power failure\\n4 - 18   - random failure\\n5 - 45   - tool wear\\n\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Perform label encoding\n",
    "df['Failure Type_encoded'] = label_encoder.fit_transform(df['Failure Type'])\n",
    "\n",
    "df['Failure Type_encoded'].value_counts()\n",
    "\n",
    "''''\n",
    "0 - 112  - heat dissipation\n",
    "1 - 9652 - no Failure\n",
    "2 - 78   - overstrain\n",
    "3 - 95   - power failure\n",
    "4 - 18   - random failure\n",
    "5 - 45   - tool wear\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>Failure Type</th>\n",
       "      <th>Failure Type_encoded</th>\n",
       "      <th>Type_L</th>\n",
       "      <th>Type_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1551</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0</td>\n",
       "      <td>No Failure</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>46.3</td>\n",
       "      <td>3</td>\n",
       "      <td>No Failure</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>298.1</td>\n",
       "      <td>308.5</td>\n",
       "      <td>1498</td>\n",
       "      <td>49.4</td>\n",
       "      <td>5</td>\n",
       "      <td>No Failure</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>298.2</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1433</td>\n",
       "      <td>39.5</td>\n",
       "      <td>7</td>\n",
       "      <td>No Failure</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9</td>\n",
       "      <td>No Failure</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Air temperature [K]  Process temperature [K]  Rotational speed [rpm]  \\\n",
       "0                298.1                    308.6                    1551   \n",
       "1                298.2                    308.7                    1408   \n",
       "2                298.1                    308.5                    1498   \n",
       "3                298.2                    308.6                    1433   \n",
       "4                298.2                    308.7                    1408   \n",
       "\n",
       "   Torque [Nm]  Tool wear [min] Failure Type  Failure Type_encoded  Type_L  \\\n",
       "0         42.8                0   No Failure                     1   False   \n",
       "1         46.3                3   No Failure                     1    True   \n",
       "2         49.4                5   No Failure                     1    True   \n",
       "3         39.5                7   No Failure                     1    True   \n",
       "4         40.0                9   No Failure                     1    True   \n",
       "\n",
       "   Type_M  \n",
       "0    True  \n",
       "1   False  \n",
       "2   False  \n",
       "3   False  \n",
       "4   False  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df, columns=['Type'], prefix='Type', drop_first=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição do conjunto de dados de entrada e do conjunto de dados de saída\n",
    "\n",
    "X_raw = df.drop(['Failure Type','Failure Type_encoded'], axis=1).values\n",
    "y_raw= df['Failure Type_encoded'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de amostras antes balanceamento: 10000\n",
      "Total de amostras por falha:\n",
      "\n",
      " Failure Type_encoded\n",
      "1    9652\n",
      "0     112\n",
      "3      95\n",
      "2      78\n",
      "5      45\n",
      "4      18\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total de amostras antes balanceamento:',df['Failure Type_encoded'].count())\n",
    "print('Total de amostras por falha:\\n\\n', df['Failure Type_encoded'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de amostras após balanceamento: 57868\n",
      "Total de amostras por falha:\n",
      "\n",
      " Type_encoded\n",
      "2    9652\n",
      "0    9649\n",
      "5    9647\n",
      "3    9645\n",
      "4    9645\n",
      "1    9630\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#implementação do método SMOTE no conunto de dados\n",
    "smt=SMOTETomek(sampling_strategy='auto',random_state=42)\n",
    "X_resampled, y_resampled = smt.fit_resample(X_raw, y_raw)\n",
    "\n",
    "# Convertendo para dataframe do pandas\n",
    "df_resampled = pd.DataFrame(X_resampled, columns=[f'feature_{i}' for i in range(X_resampled.shape[1])])\n",
    "df_resampled['Type_encoded'] = y_resampled \n",
    "\n",
    "df_resampled.head()\n",
    "\n",
    "#distribuição das classes após balanceamento\n",
    "print('Total de amostras após balanceamento:',df_resampled['Type_encoded'].count())\n",
    "print('Total de amostras por falha:\\n\\n', df_resampled['Type_encoded'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temp_Ar</th>\n",
       "      <th>Temp_Pr</th>\n",
       "      <th>Vel_Spindle</th>\n",
       "      <th>Torque</th>\n",
       "      <th>Desg_Ferr</th>\n",
       "      <th>Mat_L</th>\n",
       "      <th>Mat_M</th>\n",
       "      <th>Tipo_Falha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1551.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>46.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>298.1</td>\n",
       "      <td>308.5</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>49.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>298.2</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1433.0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temp_Ar  Temp_Pr  Vel_Spindle  Torque  Desg_Ferr  Mat_L  Mat_M  Tipo_Falha\n",
       "0    298.1    308.6       1551.0    42.8        0.0    0.0    1.0           1\n",
       "1    298.2    308.7       1408.0    46.3        3.0    1.0    0.0           1\n",
       "2    298.1    308.5       1498.0    49.4        5.0    1.0    0.0           1\n",
       "3    298.2    308.6       1433.0    39.5        7.0    1.0    0.0           1\n",
       "4    298.2    308.7       1408.0    40.0        9.0    1.0    0.0           1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resampled = df_resampled.rename(columns={'feature_0':'Temp_Ar'})\n",
    "df_resampled = df_resampled.rename(columns={'feature_1':'Temp_Pr'})\n",
    "df_resampled = df_resampled.rename(columns={'feature_2':'Vel_Spindle'})\n",
    "df_resampled = df_resampled.rename(columns={'feature_3':'Torque'})\n",
    "df_resampled = df_resampled.rename(columns={'feature_4':'Desg_Ferr'})\n",
    "df_resampled = df_resampled.rename(columns={'feature_5':'Mat_L'})\n",
    "df_resampled = df_resampled.rename(columns={'feature_6':'Mat_M'})\n",
    "\n",
    "df_resampled = df_resampled.rename(columns={'Type_encoded':'Tipo_Falha'})\n",
    "\n",
    "df_resampled.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = df_resampled.drop(['Tipo_Falha'], axis=\"columns\")\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "X   = scaler.fit_transform(X_)    \n",
    "joblib.dump(scaler, 'minmax_scaler.pkl')\n",
    "\n",
    "y = df_resampled['Tipo_Falha']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(X_train, y_train, X_test, y_test, param_grid, device):\n",
    "\n",
    "    for h_layer_size in param_grid['hidden_layer_size']:\n",
    "        for r_activation in param_grid['regularize_activation']:\n",
    "            for r_entropy in param_grid['regularize_entropy']:\n",
    "                for r_ridge in param_grid['regularize_ridge']:\n",
    "                    for b_size in param_grid['batch_size']:\n",
    "                        for w_decay in param_grid['weight_decay']:\n",
    "                            for g in param_grid['gamma']:\n",
    "                                for l in param_grid['lr']:\n",
    "\n",
    "                                    model = KANClassifier(hidden_layer_size     = h_layer_size,\n",
    "                                                          device                = device,\n",
    "                                                          regularize_activation = r_activation,\n",
    "                                                          regularize_entropy    = r_entropy,\n",
    "                                                          regularize_ridge      = r_ridge)                                   \n",
    "\n",
    "                                    print(f'Executando: layers: {h_layer_size}, activation: {r_activation}, entropy: {r_entropy}, ridge: {r_ridge}, batch size: {b_size}, decay: {w_decay}, gamma: {g}, learning reate: {l}')\n",
    "                                                                       \n",
    "                                    model.fit(X_train,y_train,batch_size = b_size,lr = l,weight_decay = w_decay,gamma = g)\n",
    "\n",
    "                                    y_train_pred = model.predict(X_train)\n",
    "                                    f1_train = f1_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "                                    y_test_pred = model.predict(X_test)\n",
    "                                    f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "                                    acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "                                    result = {'f1_train' : f1_train,'f1_test'  : f1_test, 'accuracy' : acc}\n",
    "\n",
    "                                    results.append(result)   \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executando: layers: 256, activation: 0.4, entropy: 0.4, ridge: 0.05, batch size: 64, decay: 0.005, gamma: 0.4, learning reate: 0.05\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "cannot assign module before Module.__init__() call",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_layer_size\u001b[39m\u001b[38;5;124m'\u001b[39m     : [\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m1024\u001b[39m],\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregularize_activation\u001b[39m\u001b[38;5;124m'\u001b[39m : [\u001b[38;5;241m0.4\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.6\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m                    : [\u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;241m0.07\u001b[39m, \u001b[38;5;241m0.1\u001b[39m]\n\u001b[1;32m     10\u001b[0m     }\n\u001b[0;32m---> 13\u001b[0m grid_results \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m best_result_Accuracy        \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(results, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     16\u001b[0m best_result_F1_Score_train  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(results, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_train\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[53], line 20\u001b[0m, in \u001b[0;36mgrid_search\u001b[0;34m(X_train, y_train, X_test, y_test, param_grid, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m KANClassifier(hidden_layer_size     \u001b[38;5;241m=\u001b[39m h_layer_size,\n\u001b[1;32m     13\u001b[0m                       device                \u001b[38;5;241m=\u001b[39m device,\n\u001b[1;32m     14\u001b[0m                       regularize_activation \u001b[38;5;241m=\u001b[39m r_activation,\n\u001b[1;32m     15\u001b[0m                       regularize_entropy    \u001b[38;5;241m=\u001b[39m r_entropy,\n\u001b[1;32m     16\u001b[0m                       regularize_ridge      \u001b[38;5;241m=\u001b[39m r_ridge)                                   \n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExecutando: layers: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh_layer_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, activation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr_activation\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, entropy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr_entropy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, ridge: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr_ridge\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, batch size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, decay: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mw_decay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, gamma: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, learning reate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ml\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m,\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mw_decay\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_train)\n\u001b[1;32m     23\u001b[0m f1_train \u001b[38;5;241m=\u001b[39m f1_score(y_train, y_train_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[33], line 65\u001b[0m, in \u001b[0;36mKAN.fit\u001b[0;34m(self, X, y, batch_size, lr, weight_decay, gamma)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m KANGAMModule(\n\u001b[1;32m     59\u001b[0m         num_features\u001b[38;5;241m=\u001b[39mnum_features,\n\u001b[1;32m     60\u001b[0m         layers_hidden\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layer_sizes,\n\u001b[1;32m     61\u001b[0m         n_classes\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[1;32m     63\u001b[0m     )\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m \u001b[38;5;241m=\u001b[39m KANModule(\n\u001b[1;32m     66\u001b[0m         layers_hidden\u001b[38;5;241m=\u001b[39m[num_features] \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layer_sizes \u001b[38;5;241m+\u001b[39m [num_outputs],\n\u001b[1;32m     68\u001b[0m     )\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     70\u001b[0m X_train, X_tune, y_train, y_tune \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[1;32m     71\u001b[0m     X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     73\u001b[0m dset_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mTensorDataset(X_train, y_train)\n",
      "File \u001b[0;32m~/anaconda3/envs/diss_3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1737\u001b[0m, in \u001b[0;36mModule.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Module):\n\u001b[1;32m   1736\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m modules \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1737\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1738\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot assign module before Module.__init__() call\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1739\u001b[0m     remove_from(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_persistent_buffers_set)\n\u001b[1;32m   1740\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m _global_module_registration_hooks\u001b[38;5;241m.\u001b[39mvalues():\n",
      "\u001b[0;31mAttributeError\u001b[0m: cannot assign module before Module.__init__() call"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_size'     : [256, 512, 1024],\n",
    "    'regularize_activation' : [0.4, 0.5, 0.6],\n",
    "    'regularize_entropy'    : [0.4, 0.5, 0.6], \n",
    "    'regularize_ridge'      : [0.05, 0.1, 0.2], \n",
    "    'batch_size'            : [64, 128, 512],    \n",
    "    'weight_decay'          : [0.005, 0.01, 0.03],\n",
    "    'gamma'                 : [0.4, 0.5, 0.6],\n",
    "    'lr'                    : [0.05, 0.07, 0.1]\n",
    "    }\n",
    "\n",
    "\n",
    "grid_results = grid_search(X_train, y_train, X_test, y_test, param_grid, device)\n",
    "\n",
    "best_result_Accuracy        = max(results, key=lambda x: x['accuracy'])\n",
    "best_result_F1_Score_train  = max(results, key=lambda x: x['f1_train'])\n",
    "best_result_F1_Score_test   = max(results, key=lambda x: x['f1_test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''''\n",
    "\n",
    "    for par in ParameterGrid(param_grid):\n",
    "\n",
    "        print('Configuração em execução: ',par)\n",
    "\n",
    "        model = KANClassifier(hidden_layer_size     = param_grid['hidden_layer_size'],\n",
    "                              device                = device,\n",
    "                              regularize_activation = param_grid['regularize_activation'],\n",
    "                              regularize_entropy    = param_grid['regularize_entropy'],\n",
    "                              regularize_ridge      = param_grid['regularize_ridge'])\n",
    "\n",
    "\n",
    "        model.fit(X_train, y_train, batch_size=param_grid['batch_size'], lr= param_grid['lr'], weight_decay=['weight_decay'], gamma=['gamma'])\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        f1_train = f1_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "        acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "        result = { \n",
    "                'f1_train' : f1_train,\n",
    "                'f1_test'  : f1_test,\n",
    "                'accuracy' : acc\n",
    "        }\n",
    "\n",
    "        results.append(result)\n",
    "    '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diss_3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
